{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conge\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maze is a 2d Numpy array of floats between 0.0 to 1.0\n",
    "# 1.0 corresponds to a free cell, and 0.0 an occupied cell\n",
    "# rat = (row, col) initial rat position (defaults to (0,0))\n",
    "\n",
    "class Qmaze(object):\n",
    "    def __init__(self, maze, rat=(0,0)):\n",
    "        self._maze = np.array(maze)\n",
    "        nrows, ncols = self._maze.shape\n",
    "        self.target = (nrows-1, ncols-1)   # target cell where the \"cheese\" is\n",
    "        self.free_cells = [(r,c) for r in range(nrows) for c in range(ncols) if self._maze[r,c] == 1.0]\n",
    "        self.free_cells.remove(self.target)\n",
    "        if self._maze[self.target] == 0.0:\n",
    "            raise Exception(\"Invalid maze: target cell cannot be blocked!\")\n",
    "        if not rat in self.free_cells:\n",
    "            raise Exception(\"Invalid Rat Location: must sit on a free cell\")\n",
    "        self.reset(rat)\n",
    "\n",
    "    def reset(self, rat):\n",
    "        self.rat = rat\n",
    "        self.maze = np.copy(self._maze)\n",
    "        nrows, ncols = self.maze.shape\n",
    "        row, col = rat\n",
    "        self.maze[row, col] = rat_mark\n",
    "        self.state = (row, col, 'start')\n",
    "        self.min_reward = -0.5 * self.maze.size\n",
    "        self.total_reward = 0\n",
    "        self.visited = set()\n",
    "\n",
    "    def update_state(self, action):\n",
    "        nrows, ncols = self.maze.shape\n",
    "        nrow, ncol, nmode = rat_row, rat_col, mode = self.state\n",
    "\n",
    "        if self.maze[rat_row, rat_col] > 0.0:\n",
    "            self.visited.add((rat_row, rat_col))  # mark visited cell\n",
    "\n",
    "        valid_actions = self.valid_actions()\n",
    "                \n",
    "        if not valid_actions:\n",
    "            nmode = 'blocked'\n",
    "        elif action in valid_actions:\n",
    "            nmode = 'valid'\n",
    "            if action == LEFT:\n",
    "                ncol -= 1\n",
    "            elif action == UP:\n",
    "                nrow -= 1\n",
    "            if action == RIGHT:\n",
    "                ncol += 1\n",
    "            elif action == DOWN:\n",
    "                nrow += 1\n",
    "        else:                  # invalid action, no change in rat position\n",
    "            mode = 'invalid'\n",
    "\n",
    "        # new state\n",
    "        self.state = (nrow, ncol, nmode)\n",
    "\n",
    "    def get_reward(self):\n",
    "        rat_row, rat_col, mode = self.state\n",
    "        nrows, ncols = self.maze.shape\n",
    "        if rat_row == nrows-1 and rat_col == ncols-1:\n",
    "            return 1\n",
    "        return 0\n",
    "#         if mode == 'blocked':\n",
    "#             return self.min_reward - 1\n",
    "#         if (rat_row, rat_col) in self.visited:\n",
    "#             return 0\n",
    "#         if mode == 'invalid':\n",
    "#             return 0\n",
    "#         if mode == 'valid':\n",
    "#             return 0\n",
    "\n",
    "    def act(self, action):\n",
    "        self.update_state(action)\n",
    "        reward = self.get_reward()\n",
    "        self.total_reward += reward\n",
    "        status = self.game_status()\n",
    "        envstate = self.observe()\n",
    "        return envstate, reward, status\n",
    "\n",
    "    def observe(self):\n",
    "        canvas = self.draw_env()\n",
    "        envstate = canvas.reshape((1, -1))\n",
    "        return envstate\n",
    "\n",
    "    def draw_env(self):\n",
    "        canvas = np.copy(self.maze)\n",
    "        nrows, ncols = self.maze.shape\n",
    "        # clear all visual marks\n",
    "        for r in range(nrows):\n",
    "            for c in range(ncols):\n",
    "                if canvas[r,c] > 0.0:\n",
    "                    canvas[r,c] = 1.0\n",
    "        # draw the rat\n",
    "        row, col, valid = self.state\n",
    "        canvas[row, col] = rat_mark\n",
    "        return canvas\n",
    "\n",
    "    def game_status(self):\n",
    "        if self.total_reward < self.min_reward:\n",
    "            return 'lose'\n",
    "        rat_row, rat_col, mode = self.state\n",
    "        nrows, ncols = self.maze.shape\n",
    "        if rat_row == nrows-1 and rat_col == ncols-1:\n",
    "            return 'win'\n",
    "\n",
    "        return 'not_over'\n",
    "\n",
    "    def valid_actions(self, cell=None):\n",
    "        if cell is None:\n",
    "            row, col, mode = self.state\n",
    "        else:\n",
    "            row, col = cell\n",
    "        actions = [0, 1, 2, 3]\n",
    "        nrows, ncols = self.maze.shape\n",
    "        if row == 0:\n",
    "            actions.remove(1)\n",
    "        elif row == nrows-1:\n",
    "            actions.remove(3)\n",
    "\n",
    "        if col == 0:\n",
    "            actions.remove(0)\n",
    "        elif col == ncols-1:\n",
    "            actions.remove(2)\n",
    "\n",
    "        if row>0 and self.maze[row-1,col] == 0.0:\n",
    "            actions.remove(1)\n",
    "        if row<nrows-1 and self.maze[row+1,col] == 0.0:\n",
    "            actions.remove(3)\n",
    "\n",
    "        if col>0 and self.maze[row,col-1] == 0.0:\n",
    "            actions.remove(0)\n",
    "        if col<ncols-1 and self.maze[row,col+1] == 0.0:\n",
    "            actions.remove(2)\n",
    "\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural net Q_\\theta(s,a) as a class\n",
    "\n",
    "class Qfunction(object):\n",
    "    \n",
    "    def __init__(self, obssize, actsize, sess, optimizer,lr=0.5, th = 1):\n",
    "        \"\"\"\n",
    "        obssize: dimension of state space\n",
    "        actsize: dimension of action space\n",
    "        sess: sess to execute this Qfunction\n",
    "        optimizer: \n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        # build the prediction graph\n",
    "        state = tf.placeholder(tf.float32, [None, obssize])\n",
    "        \n",
    "        #Construct a FNN with 1 hidden layer\n",
    "        Layer1_nodes = 24\n",
    "        W1 = tf.get_variable('W1',[obssize, Layer1_nodes],initializer = tf.truncated_normal_initializer(stddev=.1))\n",
    "        b1 = tf.get_variable('b1',[Layer1_nodes],initializer = tf.truncated_normal_initializer(stddev=.1))\n",
    "        h1 = tf.nn.relu(tf.matmul(state,W1) + b1)\n",
    "        \n",
    "#         Layer2_nodes = 24\n",
    "#         W2 = tf.get_variable('W2',[Layer1_nodes, Layer2_nodes],initializer = tf.truncated_normal_initializer(stddev=.1))\n",
    "#         b2 = tf.get_variable('b2',[Layer2_nodes],initializer = tf.truncated_normal_initializer(stddev=.1))\n",
    "#         h2 = tf.nn.relu(tf.matmul(h1, W2) + b2)\n",
    "        \n",
    "        W2 = tf.get_variable('W2',[Layer1_nodes, actsize],initializer = tf.truncated_normal_initializer(stddev=.1))\n",
    "        b2 = tf.get_variable('b2',[actsize],initializer = tf.truncated_normal_initializer(stddev=.1))\n",
    "        h2 = tf.matmul(h1, W2) + b2        \n",
    "        \n",
    "        Qvalues = h2  # make sure it has size [None, actsize]\n",
    "        \n",
    "        # build the targets and actions\n",
    "        # targets represent the terms E[r+gamma Q] in Bellman equations\n",
    "        # actions represent a_t\n",
    "        targets = tf.placeholder(tf.float32, [None])\n",
    "        actions = tf.placeholder(tf.int32, [None])\n",
    "        actions_one_hot = tf.one_hot(actions, actsize)\n",
    "        Qpreds = tf.reduce_sum(tf.multiply(h2, actions_one_hot), axis=1) # make sure it has size [None]\n",
    "        loss_function_1 = tf.reduce_mean(tf.square(Qpreds - targets))\n",
    "        \n",
    "        \n",
    "#         a_new = tf.argmax(Qvalues, axis=1)\n",
    "#         a_new_one_hot = tf.one_hot(a_new, actsize)\n",
    "#         a_diff = a_new_one_hot - actions_one_hot\n",
    "#         loss_function_2 = tf.norm(a_diff, ord = 'fro', axis = (0,1))\n",
    "        \n",
    "        \n",
    "        Q_olds = tf.placeholder(tf.float32, [None, actsize])\n",
    "        dist_new = tf.distributions.Categorical(probs = tf.nn.softmax(Qvalues))\n",
    "        dist_old = tf.distributions.Categorical(probs = tf.nn.softmax(Q_olds))\n",
    "        diff = tf.distributions.kl_divergence(dist_new, dist_old)\n",
    "        loss_function_2 = tf.reduce_mean(tf.contrib.framework.sort(diff)[:6])\n",
    "#         loss_function_2 = tf.reduce_mean(diff)\n",
    "        \n",
    "#         self.lr = lr\n",
    "#         self.th = th\n",
    "        \n",
    "#         l1 = tf.cast(tf.less(loss_function_2, self.th), tf.float32)\n",
    "#         l2 = tf.cast(tf.greater(loss_function_2, self.th), tf.float32)\n",
    "#         self.lr = self.lr *(1.01*l1+0.99*l2)\n",
    "        \n",
    "        loss = loss_function_1 - loss_function_2\n",
    "        \n",
    "        # optimization\n",
    "        self.train_op = optimizer.minimize(loss)\n",
    "        \n",
    "        # some bookkeeping\n",
    "        self.Qvalues = Qvalues\n",
    "        self.state = state\n",
    "        self.actions = actions\n",
    "        self.targets = targets\n",
    "        self.loss = loss\n",
    "        self.sess = sess\n",
    "        self.Q_olds = Q_olds\n",
    "        \n",
    "        \n",
    "    \n",
    "    def compute_Qvalues(self, states):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return self.sess.run(self.Qvalues, feed_dict={self.state: states})\n",
    "\n",
    "    def train(self, states, actions, targets, Qolds):\n",
    "        \"\"\"\n",
    "        states: numpy array as input to compute loss (s)\n",
    "        actions: numpy array as input to compute loss (a)\n",
    "        targets: numpy array as input to compute loss (Q targets)\n",
    "        \"\"\"\n",
    "        return self.sess.run([self.loss,self.train_op], feed_dict={self.state:states, self.actions:actions, \n",
    "                                                                   self.targets:targets, self.Q_olds: Qolds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement replay buffer\n",
    "class ReplayBuffer(object):\n",
    "    \n",
    "    def __init__(self, maxlength):\n",
    "        \"\"\"\n",
    "        maxlength: max number of tuples to store in the buffer\n",
    "        if there are more tuples than maxlength, pop out the oldest tuples\n",
    "        \"\"\"\n",
    "        self.buffer = deque()\n",
    "        self.number = 0\n",
    "        self.maxlength = maxlength\n",
    "    \n",
    "    def append(self, experience):\n",
    "        \"\"\"\n",
    "        this function implements appending new experience tuple\n",
    "        experience: a tuple of the form (s,a,r,s^\\prime)\n",
    "        \"\"\"\n",
    "        self.buffer.append(experience)\n",
    "        self.number += 1\n",
    "        \n",
    "    def pop(self):\n",
    "        \"\"\"\n",
    "        pop out the oldest tuples if self.number > self.maxlength\n",
    "        \"\"\"\n",
    "        while self.number > self.maxlength:\n",
    "            self.buffer.popleft()\n",
    "            self.number -= 1\n",
    "    \n",
    "    def sample(self, batchsize):\n",
    "        \"\"\"\n",
    "        this function samples 'batchsize' experience tuples\n",
    "        batchsize: size of the minibatch to be sampled\n",
    "        return: a list of tuples of form (s,a,r,s^\\prime)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        if batchsize < self.number:\n",
    "            minibatch = random.sample(self.buffer, batchsize) \n",
    "        else:\n",
    "            minibatch = random.sample(self.buffer, self.number) \n",
    "        return minibatch  # need implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_target_update(from_scope, to_scope):\n",
    "    from_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=from_scope)\n",
    "    to_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=to_scope)\n",
    "    op = []\n",
    "    for v1, v2 in zip(from_vars, to_vars):\n",
    "        op.append(v2.assign(0.2*v1+0.8*v2))\n",
    "    return op    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maze = np.array([\n",
    "#     [ 1.,  0.,  1.,  1.,  1.,  1.,  1.],\n",
    "#     [ 1.,  1.,  1.,  0.,  0.,  1.,  0.],\n",
    "#     [ 0.,  0.,  0.,  1.,  1.,  1.,  0.],\n",
    "#     [ 1.,  1.,  1.,  1.,  0.,  0.,  1.],\n",
    "#     [ 1.,  0.,  0.,  0.,  1.,  1.,  1.],\n",
    "#     [ 1.,  0.,  1.,  1.,  1.,  1.,  1.],\n",
    "#     [ 1.,  1.,  1.,  0.,  1.,  1.,  1.]\n",
    "# ])\n",
    "maze = np.array([\n",
    "     [ 1.,  0.,  1.,  1.,  1.,  0.,  1.],\n",
    "     [ 1.,  1.,  1.,  1.,  0.,  1.,  1.],\n",
    "     [ 1.,  1.,  1.,  0.,  1.,  1.,  1.],\n",
    "     [ 0.,  1.,  1.,  1.,  1.,  1.,  0.],\n",
    "     [ 1.,  1.,  0.,  0.,  1.,  1.,  1.],\n",
    "     [ 1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "     [ 1.,  1.,  1.,  1.,  0.,  1.,  1.]\n",
    "])\n",
    "\n",
    "# maze = np.array([\n",
    "#     [ 1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "#     [ 1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "#     [ 1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "#     [ 1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "#     [ 1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "#     [ 1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "#     [ 1.,  1.,  1.,  1.,  1.,  1.,  1.]\n",
    "# ])\n",
    "\n",
    "\n",
    "visited_mark = 0.8  # Cells visited by the rat will be painted by gray 0.8\n",
    "rat_mark = 0.5      # The current rat cell will be painteg by gray 0.5\n",
    "LEFT = 0\n",
    "UP = 1\n",
    "RIGHT = 2\n",
    "DOWN = 3\n",
    "\n",
    "# Actions dictionary\n",
    "actions_dict = {\n",
    "    LEFT: 'left',\n",
    "    UP: 'up',\n",
    "    RIGHT: 'right',\n",
    "    DOWN: 'down',\n",
    "}\n",
    "\n",
    "num_actions = len(actions_dict)\n",
    "\n",
    "rat_cell = (0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(qmaze, file_name = 'Maze'):\n",
    "    plt.grid('on')\n",
    "    nrows, ncols = qmaze.maze.shape\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks(np.arange(0.5, nrows, 1))\n",
    "    ax.set_yticks(np.arange(0.5, ncols, 1))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    canvas = np.copy(qmaze.maze)\n",
    "    for row,col in qmaze.visited:\n",
    "        canvas[row,col] = 0.6\n",
    "    rat_row, rat_col, _ = qmaze.state\n",
    "    canvas[rat_row, rat_col] = 0.3   # rat cell\n",
    "    canvas[nrows-1, ncols-1] = 0.9 # cheese cell\n",
    "    img = plt.imshow(canvas, interpolation='none', cmap='gray')\n",
    "    plt.imshow(canvas, interpolation='none', cmap='gray')\n",
    "    plt.savefig(file_name)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conge\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:424: MatplotlibDeprecationWarning: \n",
      "Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warn_deprecated(\"2.2\", \"Passing one of 'on', 'true', 'off', 'false' as a \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x254dad60160>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = Qmaze(maze)\n",
    "show(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_obs(obs, maze_size = 7):\n",
    "    for i in range(maze_size):\n",
    "        for j in range(maze_size):\n",
    "            if obs[i,j] == .5:\n",
    "                return (i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 1 episode.Reward =0.\n",
      "Finished 2 episode.Reward =0.\n",
      "Finished 3 episode.Reward =0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conge\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:424: MatplotlibDeprecationWarning: \n",
      "Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warn_deprecated(\"2.2\", \"Passing one of 'on', 'true', 'off', 'false' as a \"\n",
      "C:\\Users\\conge\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\conge\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 4 episode.Reward =0.\n",
      "Finished 5 episode.Reward =0.\n",
      "Finished 6 episode.Reward =0.\n",
      "Finished 7 episode.Reward =0.\n",
      "Finished 8 episode.Reward =0.\n",
      "Finished 9 episode.Reward =0.\n",
      "Finished 10 episode.Reward =0.\n",
      "Finished 11 episode.Reward =0.\n",
      "Finished 12 episode.Reward =0.\n",
      "Finished 13 episode.Reward =0.\n",
      "Finished 14 episode.Reward =1.\n",
      "Finished 15 episode.Reward =0.\n",
      "Finished 16 episode.Reward =0.\n",
      "Finished 17 episode.Reward =0.\n",
      "Finished 18 episode.Reward =1.\n",
      "Finished 19 episode.Reward =1.\n",
      "Finished 20 episode.Reward =0.\n",
      "Finished 21 episode.Reward =0.\n",
      "Finished 22 episode.Reward =0.\n",
      "Finished 23 episode.Reward =0.\n",
      "Finished 24 episode.Reward =0.\n",
      "Finished 25 episode.Reward =1.\n",
      "Finished 26 episode.Reward =0.\n",
      "Finished 27 episode.Reward =1.\n",
      "Finished 28 episode.Reward =0.\n",
      "Finished 29 episode.Reward =0.\n",
      "Finished 30 episode.Reward =1.\n",
      "Finished 31 episode.Reward =0.\n",
      "Finished 32 episode.Reward =0.\n",
      "Finished 33 episode.Reward =1.\n",
      "Finished 34 episode.Reward =1.\n",
      "Finished 35 episode.Reward =0.\n",
      "Finished 36 episode.Reward =1.\n",
      "Finished 37 episode.Reward =0.\n",
      "Finished 38 episode.Reward =0.\n",
      "Finished 39 episode.Reward =0.\n",
      "Finished 40 episode.Reward =1.\n",
      "Finished 41 episode.Reward =1.\n",
      "Finished 42 episode.Reward =1.\n",
      "Finished 43 episode.Reward =0.\n",
      "Finished 44 episode.Reward =0.\n",
      "Finished 45 episode.Reward =0.\n",
      "Finished 46 episode.Reward =1.\n",
      "Finished 47 episode.Reward =1.\n",
      "Finished 48 episode.Reward =0.\n",
      "Finished 49 episode.Reward =1.\n",
      "Finished 50 episode.Reward =0.\n",
      "Finished 51 episode.Reward =1.\n",
      "Finished 52 episode.Reward =1.\n",
      "Finished 53 episode.Reward =0.\n",
      "Finished 54 episode.Reward =1.\n",
      "Finished 55 episode.Reward =1.\n",
      "Finished 56 episode.Reward =1.\n",
      "Finished 57 episode.Reward =0.\n",
      "Finished 58 episode.Reward =1.\n",
      "Finished 59 episode.Reward =1.\n",
      "Finished 60 episode.Reward =0.\n",
      "Finished 61 episode.Reward =0.\n",
      "Finished 62 episode.Reward =0.\n",
      "Finished 63 episode.Reward =1.\n",
      "Finished 64 episode.Reward =0.\n",
      "Finished 65 episode.Reward =1.\n",
      "Finished 66 episode.Reward =0.\n",
      "Finished 67 episode.Reward =1.\n",
      "Finished 68 episode.Reward =1.\n",
      "Finished 69 episode.Reward =0.\n",
      "Finished 70 episode.Reward =0.\n",
      "Finished 71 episode.Reward =0.\n",
      "Finished 72 episode.Reward =0.\n",
      "Finished 73 episode.Reward =1.\n",
      "Finished 74 episode.Reward =0.\n",
      "Finished 75 episode.Reward =0.\n",
      "Finished 76 episode.Reward =0.\n",
      "Finished 77 episode.Reward =1.\n",
      "Finished 78 episode.Reward =0.\n",
      "Finished 79 episode.Reward =1.\n",
      "Finished 80 episode.Reward =1.\n",
      "Finished 81 episode.Reward =1.\n",
      "Finished 82 episode.Reward =1.\n",
      "Finished 83 episode.Reward =0.\n",
      "Finished 84 episode.Reward =1.\n",
      "Finished 85 episode.Reward =0.\n",
      "Finished 86 episode.Reward =1.\n",
      "Finished 87 episode.Reward =0.\n",
      "Finished 88 episode.Reward =0.\n",
      "Finished 89 episode.Reward =0.\n",
      "Finished 90 episode.Reward =1.\n",
      "Finished 91 episode.Reward =0.\n",
      "Finished 92 episode.Reward =1.\n",
      "Finished 93 episode.Reward =0.\n",
      "Finished 94 episode.Reward =1.\n",
      "Finished 95 episode.Reward =0.\n",
      "Finished 96 episode.Reward =0.\n",
      "Finished 97 episode.Reward =1.\n",
      "Finished 98 episode.Reward =1.\n",
      "Finished 99 episode.Reward =1.\n",
      "Finished 100 episode.Reward =0.\n",
      "Finished 101 episode.Reward =0.\n",
      "Finished 102 episode.Reward =1.\n",
      "Finished 103 episode.Reward =1.\n",
      "Finished 104 episode.Reward =1.\n",
      "Finished 105 episode.Reward =1.\n",
      "Finished 106 episode.Reward =1.\n",
      "Finished 107 episode.Reward =0.\n",
      "Finished 108 episode.Reward =1.\n",
      "Finished 109 episode.Reward =0.\n",
      "Finished 110 episode.Reward =1.\n",
      "Finished 111 episode.Reward =1.\n",
      "Finished 112 episode.Reward =1.\n",
      "Finished 113 episode.Reward =0.\n",
      "Finished 114 episode.Reward =1.\n",
      "Finished 115 episode.Reward =0.\n",
      "Finished 116 episode.Reward =1.\n",
      "Finished 117 episode.Reward =0.\n",
      "Finished 118 episode.Reward =1.\n",
      "Finished 119 episode.Reward =0.\n",
      "Finished 120 episode.Reward =1.\n",
      "Finished 121 episode.Reward =1.\n",
      "Finished 122 episode.Reward =1.\n",
      "Finished 123 episode.Reward =1.\n",
      "Finished 124 episode.Reward =1.\n",
      "Finished 125 episode.Reward =0.\n",
      "Finished 126 episode.Reward =0.\n",
      "Finished 127 episode.Reward =0.\n",
      "Finished 128 episode.Reward =0.\n",
      "Finished 129 episode.Reward =1.\n",
      "Finished 130 episode.Reward =0.\n",
      "Finished 131 episode.Reward =1.\n",
      "Finished 132 episode.Reward =1.\n",
      "Finished 133 episode.Reward =0.\n",
      "Finished 134 episode.Reward =0.\n",
      "Finished 135 episode.Reward =0.\n",
      "Finished 136 episode.Reward =1.\n",
      "Finished 137 episode.Reward =0.\n",
      "Finished 138 episode.Reward =0.\n",
      "Finished 139 episode.Reward =0.\n",
      "Finished 140 episode.Reward =1.\n",
      "Finished 141 episode.Reward =1.\n",
      "Finished 142 episode.Reward =1.\n",
      "Finished 143 episode.Reward =0.\n",
      "Finished 144 episode.Reward =1.\n",
      "Finished 145 episode.Reward =1.\n",
      "Finished 146 episode.Reward =0.\n",
      "Finished 147 episode.Reward =1.\n",
      "Finished 148 episode.Reward =0.\n",
      "Finished 149 episode.Reward =0.\n",
      "Finished 150 episode.Reward =1.\n",
      "Finished 151 episode.Reward =0.\n",
      "Finished 152 episode.Reward =0.\n",
      "Finished 153 episode.Reward =1.\n",
      "Finished 154 episode.Reward =1.\n",
      "Finished 155 episode.Reward =1.\n",
      "Finished 156 episode.Reward =1.\n",
      "Finished 157 episode.Reward =0.\n",
      "Finished 158 episode.Reward =0.\n",
      "Finished 159 episode.Reward =1.\n",
      "Finished 160 episode.Reward =1.\n",
      "Finished 161 episode.Reward =1.\n",
      "Finished 162 episode.Reward =1.\n",
      "Finished 163 episode.Reward =0.\n",
      "Finished 164 episode.Reward =0.\n",
      "Finished 165 episode.Reward =0.\n",
      "Finished 166 episode.Reward =0.\n",
      "Finished 167 episode.Reward =0.\n",
      "Finished 168 episode.Reward =1.\n",
      "Finished 169 episode.Reward =1.\n",
      "Finished 170 episode.Reward =1.\n",
      "Finished 171 episode.Reward =1.\n",
      "Finished 172 episode.Reward =1.\n",
      "Finished 173 episode.Reward =0.\n",
      "Finished 174 episode.Reward =1.\n",
      "Finished 175 episode.Reward =1.\n",
      "Finished 176 episode.Reward =0.\n",
      "Finished 177 episode.Reward =1.\n",
      "Finished 178 episode.Reward =0.\n",
      "Finished 179 episode.Reward =1.\n",
      "Finished 180 episode.Reward =1.\n",
      "Finished 181 episode.Reward =0.\n",
      "Finished 182 episode.Reward =1.\n",
      "Finished 183 episode.Reward =1.\n",
      "Finished 184 episode.Reward =0.\n",
      "Finished 185 episode.Reward =1.\n",
      "Finished 186 episode.Reward =0.\n",
      "Finished 187 episode.Reward =1.\n",
      "Finished 188 episode.Reward =1.\n",
      "Finished 189 episode.Reward =0.\n",
      "Finished 190 episode.Reward =0.\n",
      "Finished 191 episode.Reward =1.\n",
      "Finished 192 episode.Reward =1.\n",
      "Finished 193 episode.Reward =0.\n",
      "Finished 194 episode.Reward =1.\n",
      "Finished 195 episode.Reward =1.\n",
      "Finished 196 episode.Reward =0.\n",
      "Finished 197 episode.Reward =1.\n",
      "Finished 198 episode.Reward =1.\n",
      "Finished 199 episode.Reward =0.\n",
      "Finished 200 episode.Reward =0.\n",
      "Finished 201 episode.Reward =0.\n",
      "Finished 202 episode.Reward =0.\n",
      "Finished 203 episode.Reward =1.\n",
      "Finished 204 episode.Reward =0.\n",
      "Finished 205 episode.Reward =1.\n",
      "Finished 206 episode.Reward =0.\n",
      "Finished 207 episode.Reward =0.\n",
      "Finished 208 episode.Reward =1.\n",
      "Finished 209 episode.Reward =0.\n",
      "Finished 210 episode.Reward =0.\n",
      "Finished 211 episode.Reward =0.\n",
      "Finished 212 episode.Reward =0.\n",
      "Finished 213 episode.Reward =0.\n",
      "Finished 214 episode.Reward =0.\n",
      "Finished 215 episode.Reward =0.\n",
      "Finished 216 episode.Reward =0.\n",
      "Finished 217 episode.Reward =1.\n",
      "Finished 218 episode.Reward =0.\n",
      "Finished 219 episode.Reward =0.\n",
      "Finished 220 episode.Reward =0.\n",
      "Finished 221 episode.Reward =0.\n",
      "Finished 222 episode.Reward =1.\n",
      "Finished 223 episode.Reward =0.\n",
      "Finished 224 episode.Reward =0.\n",
      "Finished 225 episode.Reward =0.\n",
      "Finished 226 episode.Reward =1.\n",
      "Finished 227 episode.Reward =0.\n",
      "Finished 228 episode.Reward =0.\n",
      "Finished 229 episode.Reward =0.\n",
      "Finished 230 episode.Reward =1.\n",
      "Finished 231 episode.Reward =0.\n",
      "Finished 232 episode.Reward =0.\n",
      "Finished 233 episode.Reward =0.\n",
      "Finished 234 episode.Reward =0.\n",
      "Finished 235 episode.Reward =0.\n",
      "Finished 236 episode.Reward =0.\n",
      "Finished 237 episode.Reward =0.\n",
      "Finished 238 episode.Reward =0.\n",
      "Finished 239 episode.Reward =0.\n",
      "Finished 240 episode.Reward =0.\n",
      "Finished 241 episode.Reward =0.\n",
      "Finished 242 episode.Reward =0.\n",
      "Finished 243 episode.Reward =0.\n",
      "Finished 244 episode.Reward =1.\n",
      "Finished 245 episode.Reward =0.\n",
      "Finished 246 episode.Reward =0.\n",
      "Finished 247 episode.Reward =0.\n",
      "Finished 248 episode.Reward =0.\n",
      "Finished 249 episode.Reward =0.\n",
      "Finished 250 episode.Reward =0.\n",
      "Finished 251 episode.Reward =0.\n",
      "Finished 252 episode.Reward =0.\n",
      "Finished 253 episode.Reward =0.\n",
      "Finished 254 episode.Reward =0.\n",
      "Finished 255 episode.Reward =0.\n",
      "Finished 256 episode.Reward =0.\n",
      "Finished 257 episode.Reward =0.\n",
      "Finished 258 episode.Reward =0.\n",
      "Finished 259 episode.Reward =0.\n",
      "Finished 260 episode.Reward =0.\n",
      "Finished 261 episode.Reward =0.\n",
      "Finished 262 episode.Reward =0.\n",
      "Finished 263 episode.Reward =0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 264 episode.Reward =0.\n",
      "Finished 265 episode.Reward =0.\n",
      "Finished 266 episode.Reward =0.\n",
      "Finished 267 episode.Reward =0.\n",
      "Finished 268 episode.Reward =0.\n",
      "Finished 269 episode.Reward =0.\n",
      "Finished 270 episode.Reward =0.\n",
      "Finished 271 episode.Reward =0.\n",
      "Finished 272 episode.Reward =1.\n",
      "Finished 273 episode.Reward =0.\n",
      "Finished 274 episode.Reward =0.\n",
      "Finished 275 episode.Reward =0.\n",
      "Finished 276 episode.Reward =0.\n",
      "Finished 277 episode.Reward =0.\n",
      "Finished 278 episode.Reward =0.\n",
      "Finished 279 episode.Reward =0.\n",
      "Finished 280 episode.Reward =0.\n",
      "Finished 281 episode.Reward =0.\n",
      "Finished 282 episode.Reward =0.\n",
      "Finished 283 episode.Reward =0.\n",
      "Finished 284 episode.Reward =1.\n",
      "Finished 285 episode.Reward =1.\n",
      "Finished 286 episode.Reward =0.\n",
      "Finished 287 episode.Reward =0.\n",
      "Finished 288 episode.Reward =0.\n",
      "Finished 289 episode.Reward =0.\n",
      "Finished 290 episode.Reward =0.\n",
      "Finished 291 episode.Reward =0.\n",
      "Finished 292 episode.Reward =0.\n",
      "Finished 293 episode.Reward =0.\n",
      "Finished 294 episode.Reward =0.\n",
      "Finished 295 episode.Reward =0.\n",
      "Finished 296 episode.Reward =0.\n",
      "Finished 297 episode.Reward =0.\n",
      "Finished 298 episode.Reward =0.\n",
      "Finished 299 episode.Reward =0.\n",
      "Finished 300 episode.Reward =0.\n",
      "Finished 301 episode.Reward =1.\n",
      "Finished 302 episode.Reward =0.\n",
      "Finished 303 episode.Reward =0.\n",
      "Finished 304 episode.Reward =0.\n",
      "Finished 305 episode.Reward =0.\n",
      "Finished 306 episode.Reward =0.\n",
      "Finished 307 episode.Reward =0.\n",
      "Finished 308 episode.Reward =0.\n",
      "Finished 309 episode.Reward =1.\n",
      "Finished 310 episode.Reward =0.\n",
      "Finished 311 episode.Reward =0.\n",
      "Finished 312 episode.Reward =0.\n",
      "Finished 313 episode.Reward =0.\n",
      "Finished 314 episode.Reward =0.\n",
      "Finished 315 episode.Reward =0.\n",
      "Finished 316 episode.Reward =0.\n",
      "Finished 317 episode.Reward =0.\n",
      "Finished 318 episode.Reward =0.\n",
      "Finished 319 episode.Reward =0.\n",
      "Finished 320 episode.Reward =0.\n",
      "Finished 321 episode.Reward =0.\n",
      "Finished 322 episode.Reward =0.\n",
      "Finished 323 episode.Reward =0.\n",
      "Finished 324 episode.Reward =1.\n",
      "Finished 325 episode.Reward =1.\n",
      "Finished 326 episode.Reward =0.\n",
      "Finished 327 episode.Reward =0.\n",
      "Finished 328 episode.Reward =0.\n",
      "Finished 329 episode.Reward =0.\n",
      "Finished 330 episode.Reward =0.\n",
      "Finished 331 episode.Reward =0.\n",
      "Finished 332 episode.Reward =0.\n",
      "Finished 333 episode.Reward =0.\n",
      "Finished 334 episode.Reward =1.\n",
      "Finished 335 episode.Reward =0.\n",
      "Finished 336 episode.Reward =0.\n",
      "Finished 337 episode.Reward =0.\n",
      "Finished 338 episode.Reward =0.\n",
      "Finished 339 episode.Reward =0.\n",
      "Finished 340 episode.Reward =0.\n",
      "Finished 341 episode.Reward =1.\n",
      "Finished 342 episode.Reward =0.\n",
      "Finished 343 episode.Reward =1.\n",
      "Finished 344 episode.Reward =0.\n",
      "Finished 345 episode.Reward =0.\n",
      "Finished 346 episode.Reward =0.\n",
      "Finished 347 episode.Reward =0.\n",
      "Finished 348 episode.Reward =0.\n",
      "Finished 349 episode.Reward =0.\n",
      "Finished 350 episode.Reward =0.\n",
      "Finished 351 episode.Reward =1.\n",
      "Finished 352 episode.Reward =1.\n",
      "Finished 353 episode.Reward =0.\n",
      "Finished 354 episode.Reward =1.\n",
      "Finished 355 episode.Reward =1.\n",
      "Finished 356 episode.Reward =0.\n",
      "Finished 357 episode.Reward =0.\n",
      "Finished 358 episode.Reward =0.\n",
      "Finished 359 episode.Reward =0.\n",
      "Finished 360 episode.Reward =0.\n",
      "Finished 361 episode.Reward =0.\n",
      "Finished 362 episode.Reward =0.\n",
      "Finished 363 episode.Reward =0.\n",
      "Finished 364 episode.Reward =0.\n",
      "Finished 365 episode.Reward =0.\n",
      "Finished 366 episode.Reward =0.\n",
      "Finished 367 episode.Reward =1.\n",
      "Finished 368 episode.Reward =0.\n",
      "Finished 369 episode.Reward =0.\n",
      "Finished 370 episode.Reward =0.\n",
      "Finished 371 episode.Reward =0.\n",
      "Finished 372 episode.Reward =1.\n",
      "Finished 373 episode.Reward =0.\n",
      "Finished 374 episode.Reward =0.\n",
      "Finished 375 episode.Reward =0.\n",
      "Finished 376 episode.Reward =0.\n",
      "Finished 377 episode.Reward =0.\n",
      "Finished 378 episode.Reward =1.\n",
      "Finished 379 episode.Reward =1.\n",
      "Finished 380 episode.Reward =1.\n",
      "Finished 381 episode.Reward =0.\n",
      "Finished 382 episode.Reward =0.\n",
      "Finished 383 episode.Reward =0.\n",
      "Finished 384 episode.Reward =0.\n",
      "Finished 385 episode.Reward =0.\n",
      "Finished 386 episode.Reward =0.\n",
      "Finished 387 episode.Reward =1.\n",
      "Finished 388 episode.Reward =0.\n",
      "Finished 389 episode.Reward =1.\n",
      "Finished 390 episode.Reward =0.\n",
      "Finished 391 episode.Reward =0.\n",
      "Finished 392 episode.Reward =1.\n",
      "Finished 393 episode.Reward =1.\n",
      "Finished 394 episode.Reward =0.\n",
      "Finished 395 episode.Reward =1.\n",
      "Finished 396 episode.Reward =0.\n",
      "Finished 397 episode.Reward =0.\n",
      "Finished 398 episode.Reward =0.\n",
      "Finished 399 episode.Reward =1.\n",
      "Finished 400 episode.Reward =1.\n",
      "Finished 401 episode.Reward =1.\n",
      "Finished 402 episode.Reward =0.\n",
      "Finished 403 episode.Reward =1.\n",
      "Finished 404 episode.Reward =1.\n",
      "Finished 405 episode.Reward =0.\n",
      "Finished 406 episode.Reward =0.\n",
      "Finished 407 episode.Reward =1.\n",
      "Finished 408 episode.Reward =0.\n",
      "Finished 409 episode.Reward =1.\n",
      "Finished 410 episode.Reward =1.\n",
      "Finished 411 episode.Reward =0.\n",
      "Finished 412 episode.Reward =1.\n",
      "Finished 413 episode.Reward =1.\n",
      "Finished 414 episode.Reward =1.\n",
      "Finished 415 episode.Reward =1.\n",
      "Finished 416 episode.Reward =1.\n",
      "Finished 417 episode.Reward =0.\n",
      "Finished 418 episode.Reward =1.\n",
      "Finished 419 episode.Reward =0.\n",
      "Finished 420 episode.Reward =1.\n",
      "Finished 421 episode.Reward =0.\n",
      "Finished 422 episode.Reward =0.\n",
      "Finished 423 episode.Reward =1.\n",
      "Finished 424 episode.Reward =1.\n",
      "Finished 425 episode.Reward =1.\n",
      "Finished 426 episode.Reward =1.\n",
      "Finished 427 episode.Reward =0.\n",
      "Finished 428 episode.Reward =0.\n",
      "Finished 429 episode.Reward =0.\n",
      "Finished 430 episode.Reward =0.\n",
      "Finished 431 episode.Reward =1.\n",
      "Finished 432 episode.Reward =0.\n",
      "Finished 433 episode.Reward =0.\n",
      "Finished 434 episode.Reward =1.\n",
      "Finished 435 episode.Reward =0.\n",
      "Finished 436 episode.Reward =1.\n",
      "Finished 437 episode.Reward =0.\n",
      "Finished 438 episode.Reward =0.\n",
      "Finished 439 episode.Reward =0.\n",
      "Finished 440 episode.Reward =1.\n",
      "Finished 441 episode.Reward =0.\n",
      "Finished 442 episode.Reward =0.\n",
      "Finished 443 episode.Reward =0.\n",
      "Finished 444 episode.Reward =0.\n",
      "Finished 445 episode.Reward =0.\n",
      "Finished 446 episode.Reward =0.\n",
      "Finished 447 episode.Reward =1.\n",
      "Finished 448 episode.Reward =0.\n",
      "Finished 449 episode.Reward =0.\n",
      "Finished 450 episode.Reward =1.\n",
      "Finished 451 episode.Reward =1.\n",
      "Finished 452 episode.Reward =1.\n",
      "Finished 453 episode.Reward =0.\n",
      "Finished 454 episode.Reward =0.\n",
      "Finished 455 episode.Reward =1.\n",
      "Finished 456 episode.Reward =1.\n",
      "Finished 457 episode.Reward =0.\n",
      "Finished 458 episode.Reward =0.\n",
      "Finished 459 episode.Reward =0.\n",
      "Finished 460 episode.Reward =1.\n",
      "Finished 461 episode.Reward =0.\n",
      "Finished 462 episode.Reward =1.\n",
      "Finished 463 episode.Reward =0.\n",
      "Finished 464 episode.Reward =1.\n",
      "Finished 465 episode.Reward =0.\n",
      "Finished 466 episode.Reward =1.\n",
      "Finished 467 episode.Reward =0.\n",
      "Finished 468 episode.Reward =0.\n",
      "Finished 469 episode.Reward =1.\n",
      "Finished 470 episode.Reward =0.\n",
      "Finished 471 episode.Reward =1.\n",
      "Finished 472 episode.Reward =1.\n",
      "Finished 473 episode.Reward =1.\n",
      "Finished 474 episode.Reward =1.\n",
      "Finished 475 episode.Reward =0.\n",
      "Finished 476 episode.Reward =1.\n",
      "Finished 477 episode.Reward =0.\n",
      "Finished 478 episode.Reward =0.\n",
      "Finished 479 episode.Reward =1.\n",
      "Finished 480 episode.Reward =1.\n",
      "Finished 481 episode.Reward =0.\n",
      "Finished 482 episode.Reward =1.\n",
      "Finished 483 episode.Reward =1.\n",
      "Finished 484 episode.Reward =0.\n",
      "Finished 485 episode.Reward =1.\n",
      "Finished 486 episode.Reward =1.\n",
      "Finished 487 episode.Reward =0.\n",
      "Finished 488 episode.Reward =0.\n",
      "Finished 489 episode.Reward =1.\n",
      "Finished 490 episode.Reward =1.\n",
      "Finished 491 episode.Reward =0.\n",
      "Finished 492 episode.Reward =0.\n",
      "Finished 493 episode.Reward =1.\n",
      "Finished 494 episode.Reward =1.\n",
      "Finished 495 episode.Reward =1.\n",
      "Finished 496 episode.Reward =0.\n",
      "Finished 497 episode.Reward =1.\n",
      "Finished 498 episode.Reward =1.\n",
      "Finished 499 episode.Reward =0.\n",
      "Finished 500 episode.Reward =1.\n",
      "Finished 501 episode.Reward =1.\n",
      "Finished 502 episode.Reward =1.\n",
      "Finished 503 episode.Reward =1.\n",
      "Finished 504 episode.Reward =1.\n",
      "Finished 505 episode.Reward =1.\n",
      "Finished 506 episode.Reward =1.\n",
      "Finished 507 episode.Reward =1.\n",
      "Finished 508 episode.Reward =0.\n",
      "Finished 509 episode.Reward =0.\n",
      "Finished 510 episode.Reward =0.\n",
      "Finished 511 episode.Reward =1.\n",
      "Finished 512 episode.Reward =1.\n",
      "Finished 513 episode.Reward =1.\n",
      "Finished 514 episode.Reward =1.\n",
      "Finished 515 episode.Reward =1.\n",
      "Finished 516 episode.Reward =1.\n",
      "Finished 517 episode.Reward =1.\n",
      "Finished 518 episode.Reward =1.\n",
      "Finished 519 episode.Reward =1.\n",
      "Finished 520 episode.Reward =1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 521 episode.Reward =1.\n",
      "Finished 522 episode.Reward =0.\n",
      "Finished 523 episode.Reward =1.\n",
      "Finished 524 episode.Reward =1.\n",
      "Finished 525 episode.Reward =1.\n",
      "Finished 526 episode.Reward =1.\n",
      "Finished 527 episode.Reward =0.\n",
      "Finished 528 episode.Reward =1.\n",
      "Finished 529 episode.Reward =1.\n",
      "Finished 530 episode.Reward =1.\n",
      "Finished 531 episode.Reward =1.\n",
      "Finished 532 episode.Reward =1.\n",
      "Finished 533 episode.Reward =1.\n",
      "Finished 534 episode.Reward =1.\n",
      "Finished 535 episode.Reward =0.\n",
      "Finished 536 episode.Reward =1.\n",
      "Finished 537 episode.Reward =1.\n",
      "Finished 538 episode.Reward =1.\n",
      "Finished 539 episode.Reward =1.\n",
      "Finished 540 episode.Reward =1.\n",
      "Finished 541 episode.Reward =1.\n",
      "Finished 542 episode.Reward =1.\n",
      "Finished 543 episode.Reward =1.\n",
      "Finished 544 episode.Reward =1.\n",
      "Finished 545 episode.Reward =1.\n",
      "Finished 546 episode.Reward =1.\n",
      "Finished 547 episode.Reward =1.\n",
      "Finished 548 episode.Reward =1.\n",
      "Finished 549 episode.Reward =1.\n",
      "Finished 550 episode.Reward =0.\n",
      "Finished 551 episode.Reward =1.\n",
      "Finished 552 episode.Reward =1.\n",
      "Finished 553 episode.Reward =1.\n",
      "Finished 554 episode.Reward =0.\n",
      "Finished 555 episode.Reward =1.\n",
      "Finished 556 episode.Reward =1.\n",
      "Finished 557 episode.Reward =0.\n",
      "Finished 558 episode.Reward =1.\n",
      "Finished 559 episode.Reward =1.\n",
      "Finished 560 episode.Reward =1.\n",
      "Finished 561 episode.Reward =1.\n",
      "Finished 562 episode.Reward =1.\n",
      "Finished 563 episode.Reward =1.\n",
      "Finished 564 episode.Reward =1.\n",
      "Finished 565 episode.Reward =1.\n",
      "Finished 566 episode.Reward =1.\n",
      "Finished 567 episode.Reward =1.\n",
      "Finished 568 episode.Reward =1.\n",
      "Finished 569 episode.Reward =1.\n",
      "Finished 570 episode.Reward =1.\n",
      "Finished 571 episode.Reward =1.\n",
      "Finished 572 episode.Reward =1.\n",
      "Finished 573 episode.Reward =0.\n",
      "Finished 574 episode.Reward =1.\n",
      "Finished 575 episode.Reward =0.\n",
      "Finished 576 episode.Reward =1.\n",
      "Finished 577 episode.Reward =1.\n",
      "Finished 578 episode.Reward =1.\n",
      "Finished 579 episode.Reward =1.\n",
      "Finished 580 episode.Reward =1.\n",
      "Finished 581 episode.Reward =1.\n",
      "Finished 582 episode.Reward =1.\n",
      "Finished 583 episode.Reward =1.\n",
      "Finished 584 episode.Reward =1.\n",
      "Finished 585 episode.Reward =1.\n",
      "Finished 586 episode.Reward =1.\n",
      "Finished 587 episode.Reward =1.\n",
      "Finished 588 episode.Reward =1.\n",
      "Finished 589 episode.Reward =1.\n",
      "Finished 590 episode.Reward =1.\n",
      "Finished 591 episode.Reward =1.\n",
      "Finished 592 episode.Reward =1.\n",
      "Finished 593 episode.Reward =1.\n",
      "Finished 594 episode.Reward =1.\n",
      "Finished 595 episode.Reward =1.\n",
      "Finished 596 episode.Reward =1.\n",
      "Finished 597 episode.Reward =1.\n",
      "Finished 598 episode.Reward =1.\n",
      "Finished 599 episode.Reward =0.\n",
      "Finished 600 episode.Reward =1.\n",
      "Finished 601 episode.Reward =1.\n",
      "Finished 602 episode.Reward =1.\n",
      "Finished 603 episode.Reward =1.\n",
      "Finished 604 episode.Reward =1.\n",
      "Finished 605 episode.Reward =0.\n",
      "Finished 606 episode.Reward =1.\n",
      "Finished 607 episode.Reward =1.\n",
      "Finished 608 episode.Reward =1.\n",
      "Finished 609 episode.Reward =1.\n",
      "Finished 610 episode.Reward =1.\n",
      "Finished 611 episode.Reward =1.\n",
      "Finished 612 episode.Reward =1.\n",
      "Finished 613 episode.Reward =1.\n",
      "Finished 614 episode.Reward =1.\n",
      "Finished 615 episode.Reward =1.\n",
      "Finished 616 episode.Reward =1.\n",
      "Finished 617 episode.Reward =1.\n",
      "Finished 618 episode.Reward =1.\n",
      "Finished 619 episode.Reward =1.\n",
      "Finished 620 episode.Reward =1.\n",
      "Finished 621 episode.Reward =0.\n",
      "Finished 622 episode.Reward =1.\n",
      "Finished 623 episode.Reward =1.\n",
      "Finished 624 episode.Reward =1.\n",
      "Finished 625 episode.Reward =1.\n",
      "Finished 626 episode.Reward =1.\n",
      "Finished 627 episode.Reward =1.\n",
      "Finished 628 episode.Reward =1.\n",
      "Finished 629 episode.Reward =1.\n",
      "Finished 630 episode.Reward =1.\n",
      "Finished 631 episode.Reward =1.\n",
      "Finished 632 episode.Reward =1.\n",
      "Finished 633 episode.Reward =1.\n",
      "Finished 634 episode.Reward =0.\n",
      "Finished 635 episode.Reward =1.\n",
      "Finished 636 episode.Reward =0.\n",
      "Finished 637 episode.Reward =1.\n",
      "Finished 638 episode.Reward =1.\n",
      "Finished 639 episode.Reward =1.\n",
      "Finished 640 episode.Reward =1.\n",
      "Finished 641 episode.Reward =1.\n",
      "Finished 642 episode.Reward =1.\n",
      "Finished 643 episode.Reward =1.\n",
      "Finished 644 episode.Reward =0.\n",
      "Finished 645 episode.Reward =1.\n",
      "Finished 646 episode.Reward =1.\n",
      "Finished 647 episode.Reward =1.\n",
      "Finished 648 episode.Reward =1.\n",
      "Finished 649 episode.Reward =1.\n",
      "Finished 650 episode.Reward =1.\n",
      "Finished 651 episode.Reward =1.\n",
      "Finished 652 episode.Reward =1.\n",
      "Finished 653 episode.Reward =1.\n",
      "Finished 654 episode.Reward =0.\n",
      "Finished 655 episode.Reward =1.\n",
      "Finished 656 episode.Reward =1.\n",
      "Finished 657 episode.Reward =1.\n",
      "Finished 658 episode.Reward =1.\n",
      "Finished 659 episode.Reward =1.\n",
      "Finished 660 episode.Reward =0.\n",
      "Finished 661 episode.Reward =1.\n",
      "Finished 662 episode.Reward =0.\n",
      "Finished 663 episode.Reward =1.\n",
      "Finished 664 episode.Reward =0.\n",
      "Finished 665 episode.Reward =1.\n",
      "Finished 666 episode.Reward =1.\n",
      "Finished 667 episode.Reward =1.\n",
      "Finished 668 episode.Reward =1.\n",
      "Finished 669 episode.Reward =1.\n",
      "Finished 670 episode.Reward =0.\n",
      "Finished 671 episode.Reward =1.\n",
      "Finished 672 episode.Reward =1.\n",
      "Finished 673 episode.Reward =0.\n",
      "Finished 674 episode.Reward =0.\n",
      "Finished 675 episode.Reward =1.\n",
      "Finished 676 episode.Reward =1.\n",
      "Finished 677 episode.Reward =1.\n",
      "Finished 678 episode.Reward =0.\n",
      "Finished 679 episode.Reward =1.\n",
      "Finished 680 episode.Reward =0.\n",
      "Finished 681 episode.Reward =1.\n",
      "Finished 682 episode.Reward =1.\n",
      "Finished 683 episode.Reward =0.\n",
      "Finished 684 episode.Reward =1.\n",
      "Finished 685 episode.Reward =0.\n",
      "Finished 686 episode.Reward =1.\n",
      "Finished 687 episode.Reward =0.\n",
      "Finished 688 episode.Reward =1.\n",
      "Finished 689 episode.Reward =0.\n",
      "Finished 690 episode.Reward =0.\n",
      "Finished 691 episode.Reward =0.\n",
      "Finished 692 episode.Reward =0.\n",
      "Finished 693 episode.Reward =0.\n",
      "Finished 694 episode.Reward =1.\n",
      "Finished 695 episode.Reward =1.\n",
      "Finished 696 episode.Reward =0.\n",
      "Finished 697 episode.Reward =1.\n",
      "Finished 698 episode.Reward =1.\n",
      "Finished 699 episode.Reward =0.\n",
      "Finished 700 episode.Reward =0.\n",
      "Finished 701 episode.Reward =1.\n",
      "Finished 702 episode.Reward =1.\n",
      "Finished 703 episode.Reward =1.\n",
      "Finished 704 episode.Reward =0.\n",
      "Finished 705 episode.Reward =0.\n",
      "Finished 706 episode.Reward =1.\n",
      "Finished 707 episode.Reward =1.\n",
      "Finished 708 episode.Reward =0.\n",
      "Finished 709 episode.Reward =0.\n",
      "Finished 710 episode.Reward =0.\n",
      "Finished 711 episode.Reward =0.\n",
      "Finished 712 episode.Reward =1.\n",
      "Finished 713 episode.Reward =1.\n",
      "Finished 714 episode.Reward =0.\n",
      "Finished 715 episode.Reward =0.\n",
      "Finished 716 episode.Reward =1.\n",
      "Finished 717 episode.Reward =1.\n",
      "Finished 718 episode.Reward =1.\n",
      "Finished 719 episode.Reward =0.\n",
      "Finished 720 episode.Reward =1.\n",
      "Finished 721 episode.Reward =0.\n",
      "Finished 722 episode.Reward =1.\n",
      "Finished 723 episode.Reward =0.\n",
      "Finished 724 episode.Reward =0.\n",
      "Finished 725 episode.Reward =0.\n",
      "Finished 726 episode.Reward =0.\n",
      "Finished 727 episode.Reward =1.\n",
      "Finished 728 episode.Reward =1.\n",
      "Finished 729 episode.Reward =1.\n",
      "Finished 730 episode.Reward =1.\n",
      "Finished 731 episode.Reward =0.\n",
      "Finished 732 episode.Reward =1.\n",
      "Finished 733 episode.Reward =1.\n",
      "Finished 734 episode.Reward =0.\n",
      "Finished 735 episode.Reward =1.\n",
      "Finished 736 episode.Reward =1.\n",
      "Finished 737 episode.Reward =0.\n",
      "Finished 738 episode.Reward =1.\n",
      "Finished 739 episode.Reward =1.\n",
      "Finished 740 episode.Reward =1.\n",
      "Finished 741 episode.Reward =0.\n",
      "Finished 742 episode.Reward =1.\n",
      "Finished 743 episode.Reward =0.\n",
      "Finished 744 episode.Reward =1.\n",
      "Finished 745 episode.Reward =1.\n",
      "Finished 746 episode.Reward =0.\n",
      "Finished 747 episode.Reward =1.\n",
      "Finished 748 episode.Reward =1.\n",
      "Finished 749 episode.Reward =0.\n",
      "Finished 750 episode.Reward =0.\n",
      "Finished 751 episode.Reward =0.\n",
      "Finished 752 episode.Reward =1.\n",
      "Finished 753 episode.Reward =0.\n",
      "Finished 754 episode.Reward =1.\n",
      "Finished 755 episode.Reward =1.\n",
      "Finished 756 episode.Reward =1.\n",
      "Finished 757 episode.Reward =1.\n",
      "Finished 758 episode.Reward =1.\n",
      "Finished 759 episode.Reward =1.\n",
      "Finished 760 episode.Reward =1.\n",
      "Finished 761 episode.Reward =1.\n",
      "Finished 762 episode.Reward =0.\n",
      "Finished 763 episode.Reward =1.\n",
      "Finished 764 episode.Reward =1.\n",
      "Finished 765 episode.Reward =1.\n",
      "Finished 766 episode.Reward =1.\n",
      "Finished 767 episode.Reward =1.\n",
      "Finished 768 episode.Reward =1.\n",
      "Finished 769 episode.Reward =1.\n",
      "Finished 770 episode.Reward =1.\n",
      "Finished 771 episode.Reward =1.\n",
      "Finished 772 episode.Reward =1.\n",
      "Finished 773 episode.Reward =1.\n",
      "Finished 774 episode.Reward =1.\n",
      "Finished 775 episode.Reward =1.\n",
      "Finished 776 episode.Reward =1.\n",
      "Finished 777 episode.Reward =1.\n",
      "Finished 778 episode.Reward =1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 779 episode.Reward =1.\n",
      "Finished 780 episode.Reward =1.\n",
      "Finished 781 episode.Reward =1.\n",
      "Finished 782 episode.Reward =1.\n",
      "Finished 783 episode.Reward =1.\n",
      "Finished 784 episode.Reward =1.\n",
      "Finished 785 episode.Reward =1.\n",
      "Finished 786 episode.Reward =0.\n",
      "Finished 787 episode.Reward =1.\n",
      "Finished 788 episode.Reward =1.\n",
      "Finished 789 episode.Reward =1.\n",
      "Finished 790 episode.Reward =1.\n",
      "Finished 791 episode.Reward =1.\n",
      "Finished 792 episode.Reward =1.\n",
      "Finished 793 episode.Reward =1.\n",
      "Finished 794 episode.Reward =1.\n",
      "Finished 795 episode.Reward =1.\n",
      "Finished 796 episode.Reward =0.\n",
      "Finished 797 episode.Reward =1.\n",
      "Finished 798 episode.Reward =1.\n",
      "Finished 799 episode.Reward =1.\n",
      "Finished 800 episode.Reward =1.\n",
      "Finished 801 episode.Reward =1.\n",
      "Finished 802 episode.Reward =1.\n",
      "Finished 803 episode.Reward =1.\n",
      "Finished 804 episode.Reward =1.\n",
      "Finished 805 episode.Reward =1.\n",
      "Finished 806 episode.Reward =1.\n",
      "Finished 807 episode.Reward =1.\n",
      "Finished 808 episode.Reward =1.\n",
      "Finished 809 episode.Reward =1.\n",
      "Finished 810 episode.Reward =1.\n",
      "Finished 811 episode.Reward =1.\n",
      "Finished 812 episode.Reward =1.\n",
      "Finished 813 episode.Reward =1.\n",
      "Finished 814 episode.Reward =1.\n",
      "Finished 815 episode.Reward =1.\n",
      "Finished 816 episode.Reward =1.\n",
      "Finished 817 episode.Reward =1.\n",
      "Finished 818 episode.Reward =1.\n",
      "Finished 819 episode.Reward =1.\n",
      "Finished 820 episode.Reward =1.\n",
      "Finished 821 episode.Reward =1.\n",
      "Finished 822 episode.Reward =1.\n",
      "Finished 823 episode.Reward =1.\n",
      "Finished 824 episode.Reward =1.\n",
      "Finished 825 episode.Reward =1.\n",
      "Finished 826 episode.Reward =1.\n",
      "Finished 827 episode.Reward =1.\n",
      "Finished 828 episode.Reward =1.\n",
      "Finished 829 episode.Reward =1.\n",
      "Finished 830 episode.Reward =1.\n",
      "Finished 831 episode.Reward =1.\n",
      "Finished 832 episode.Reward =1.\n",
      "Finished 833 episode.Reward =1.\n",
      "Finished 834 episode.Reward =1.\n",
      "Finished 835 episode.Reward =1.\n",
      "Finished 836 episode.Reward =1.\n",
      "Finished 837 episode.Reward =1.\n",
      "Finished 838 episode.Reward =1.\n",
      "Finished 839 episode.Reward =1.\n",
      "Finished 840 episode.Reward =1.\n",
      "Finished 841 episode.Reward =1.\n",
      "Finished 842 episode.Reward =1.\n",
      "Finished 843 episode.Reward =1.\n",
      "Finished 844 episode.Reward =1.\n",
      "Finished 845 episode.Reward =1.\n",
      "Finished 846 episode.Reward =1.\n",
      "Finished 847 episode.Reward =1.\n",
      "Finished 848 episode.Reward =1.\n",
      "Finished 849 episode.Reward =1.\n",
      "Finished 850 episode.Reward =1.\n",
      "Finished 851 episode.Reward =1.\n",
      "Finished 852 episode.Reward =1.\n",
      "Finished 853 episode.Reward =1.\n",
      "Finished 854 episode.Reward =1.\n",
      "Finished 855 episode.Reward =1.\n",
      "Finished 856 episode.Reward =1.\n",
      "Finished 857 episode.Reward =1.\n",
      "Finished 858 episode.Reward =1.\n",
      "Finished 859 episode.Reward =1.\n",
      "Finished 860 episode.Reward =1.\n",
      "Finished 861 episode.Reward =1.\n",
      "Finished 862 episode.Reward =0.\n",
      "Finished 863 episode.Reward =1.\n",
      "Finished 864 episode.Reward =1.\n",
      "Finished 865 episode.Reward =0.\n",
      "Finished 866 episode.Reward =1.\n",
      "Finished 867 episode.Reward =1.\n",
      "Finished 868 episode.Reward =1.\n",
      "Finished 869 episode.Reward =1.\n",
      "Finished 870 episode.Reward =1.\n",
      "Finished 871 episode.Reward =1.\n",
      "Finished 872 episode.Reward =0.\n",
      "Finished 873 episode.Reward =1.\n",
      "Finished 874 episode.Reward =1.\n",
      "Finished 875 episode.Reward =1.\n",
      "Finished 876 episode.Reward =1.\n",
      "Finished 877 episode.Reward =1.\n",
      "Finished 878 episode.Reward =1.\n",
      "Finished 879 episode.Reward =1.\n",
      "Finished 880 episode.Reward =1.\n",
      "Finished 881 episode.Reward =1.\n",
      "Finished 882 episode.Reward =1.\n",
      "Finished 883 episode.Reward =1.\n",
      "Finished 884 episode.Reward =1.\n",
      "Finished 885 episode.Reward =1.\n",
      "Finished 886 episode.Reward =1.\n",
      "Finished 887 episode.Reward =1.\n",
      "Finished 888 episode.Reward =1.\n",
      "Finished 889 episode.Reward =1.\n",
      "Finished 890 episode.Reward =1.\n",
      "Finished 891 episode.Reward =1.\n",
      "Finished 892 episode.Reward =1.\n",
      "Finished 893 episode.Reward =1.\n",
      "Finished 894 episode.Reward =1.\n",
      "Finished 895 episode.Reward =1.\n",
      "Finished 896 episode.Reward =1.\n",
      "Finished 897 episode.Reward =1.\n",
      "Finished 898 episode.Reward =1.\n",
      "Finished 899 episode.Reward =0.\n",
      "Finished 900 episode.Reward =1.\n",
      "Finished 901 episode.Reward =1.\n",
      "Finished 902 episode.Reward =1.\n",
      "Finished 903 episode.Reward =1.\n",
      "Finished 904 episode.Reward =1.\n",
      "Finished 905 episode.Reward =1.\n",
      "Finished 906 episode.Reward =1.\n",
      "Finished 907 episode.Reward =1.\n",
      "Finished 908 episode.Reward =1.\n",
      "Finished 909 episode.Reward =1.\n",
      "Finished 910 episode.Reward =1.\n",
      "Finished 911 episode.Reward =1.\n",
      "Finished 912 episode.Reward =1.\n",
      "Finished 913 episode.Reward =1.\n",
      "Finished 914 episode.Reward =1.\n",
      "Finished 915 episode.Reward =1.\n",
      "Finished 916 episode.Reward =1.\n",
      "Finished 917 episode.Reward =1.\n",
      "Finished 918 episode.Reward =1.\n",
      "Finished 919 episode.Reward =1.\n",
      "Finished 920 episode.Reward =1.\n",
      "Finished 921 episode.Reward =1.\n",
      "Finished 922 episode.Reward =1.\n",
      "Finished 923 episode.Reward =1.\n",
      "Finished 924 episode.Reward =1.\n",
      "Finished 925 episode.Reward =1.\n",
      "Finished 926 episode.Reward =1.\n",
      "Finished 927 episode.Reward =1.\n",
      "Finished 928 episode.Reward =1.\n",
      "Finished 929 episode.Reward =1.\n",
      "Finished 930 episode.Reward =1.\n",
      "Finished 931 episode.Reward =1.\n",
      "Finished 932 episode.Reward =1.\n",
      "Finished 933 episode.Reward =1.\n",
      "Finished 934 episode.Reward =1.\n",
      "Finished 935 episode.Reward =1.\n",
      "Finished 936 episode.Reward =1.\n",
      "Finished 937 episode.Reward =1.\n",
      "Finished 938 episode.Reward =1.\n",
      "Finished 939 episode.Reward =1.\n",
      "Finished 940 episode.Reward =1.\n",
      "Finished 941 episode.Reward =1.\n",
      "Finished 942 episode.Reward =1.\n",
      "Finished 943 episode.Reward =1.\n",
      "Finished 944 episode.Reward =1.\n",
      "Finished 945 episode.Reward =1.\n",
      "Finished 946 episode.Reward =1.\n",
      "Finished 947 episode.Reward =1.\n",
      "Finished 948 episode.Reward =1.\n",
      "Finished 949 episode.Reward =1.\n",
      "Finished 950 episode.Reward =1.\n",
      "Finished 951 episode.Reward =1.\n",
      "Finished 952 episode.Reward =1.\n",
      "Finished 953 episode.Reward =1.\n",
      "Finished 954 episode.Reward =1.\n",
      "Finished 955 episode.Reward =1.\n",
      "Finished 956 episode.Reward =1.\n",
      "Finished 957 episode.Reward =1.\n",
      "Finished 958 episode.Reward =1.\n",
      "Finished 959 episode.Reward =1.\n",
      "Finished 960 episode.Reward =1.\n",
      "Finished 961 episode.Reward =1.\n",
      "Finished 962 episode.Reward =1.\n",
      "Finished 963 episode.Reward =1.\n",
      "Finished 964 episode.Reward =1.\n",
      "Finished 965 episode.Reward =1.\n",
      "Finished 966 episode.Reward =1.\n",
      "Finished 967 episode.Reward =1.\n",
      "Finished 968 episode.Reward =1.\n",
      "Finished 969 episode.Reward =1.\n",
      "Finished 970 episode.Reward =1.\n",
      "Finished 971 episode.Reward =1.\n",
      "Finished 972 episode.Reward =1.\n",
      "Finished 973 episode.Reward =1.\n",
      "Finished 974 episode.Reward =1.\n",
      "Finished 975 episode.Reward =1.\n",
      "Finished 976 episode.Reward =1.\n",
      "Finished 977 episode.Reward =1.\n",
      "Finished 978 episode.Reward =1.\n",
      "Finished 979 episode.Reward =1.\n",
      "Finished 980 episode.Reward =1.\n",
      "Finished 981 episode.Reward =1.\n",
      "Finished 982 episode.Reward =1.\n",
      "Finished 983 episode.Reward =1.\n",
      "Finished 984 episode.Reward =1.\n",
      "Finished 985 episode.Reward =1.\n",
      "Finished 986 episode.Reward =1.\n",
      "Finished 987 episode.Reward =1.\n",
      "Finished 988 episode.Reward =0.\n",
      "Finished 989 episode.Reward =1.\n",
      "Finished 990 episode.Reward =1.\n",
      "Finished 991 episode.Reward =1.\n",
      "Finished 992 episode.Reward =1.\n",
      "Finished 993 episode.Reward =1.\n",
      "Finished 994 episode.Reward =1.\n",
      "Finished 995 episode.Reward =1.\n",
      "Finished 996 episode.Reward =1.\n",
      "Finished 997 episode.Reward =1.\n",
      "Finished 998 episode.Reward =1.\n",
      "Finished 999 episode.Reward =1.\n",
      "Finished 1000 episode.Reward =1.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# parameter initializations\n",
    "lr = 1e-3  # learning rate for gradient update\n",
    "batchsize = 100  # batchsize for buffer sampling\n",
    "maxlength = 10000  # max number of tuples held by buffer\n",
    "maxstep = 100\n",
    "\n",
    "tau = 100  # time steps for target update\n",
    "episodes = 1000 # number of episodes to run\n",
    "initialsize = 500  # initial time steps before start updating\n",
    "epsilon_min = 0.01 # constant for exploration\n",
    "epsilon_decay = 0.999\n",
    "gamma = .99  # discount\n",
    "\n",
    "reward_record = []\n",
    "evaluation_record = []\n",
    "\n",
    "# initialize environment\n",
    "env = Qmaze(maze)\n",
    "obssize = 49\n",
    "actsize = num_actions\n",
    "\n",
    "# initialize tensorflow session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "# initialize networks\n",
    "with tf.variable_scope(\"principal\"):\n",
    "    Qprincipal = Qfunction(obssize, actsize, sess, optimizer)\n",
    "with tf.variable_scope(\"target\"):\n",
    "    Qtarget = Qfunction(obssize, actsize, sess, optimizer)\n",
    "\n",
    "# build ops\n",
    "update = build_target_update(\"principal\", \"target\")  # call sess.run(update) to copy\n",
    "                                                     # from principal to target\n",
    "\n",
    "# initialization of graph and buffer\n",
    "sess.run(tf.global_variables_initializer())\n",
    "buffer = ReplayBuffer(maxlength)\n",
    "sess.run(update)\n",
    "\n",
    "# main iteration\n",
    "# YOUR CODE HERE\n",
    "counter = 0\n",
    "epsilon =1.0\n",
    "for e in range(episodes):\n",
    "    env.reset(rat_cell)\n",
    "    done = 'not_over'\n",
    "    rewardsum = 0\n",
    "    epsilon = max(0.1,epsilon * 0.995)\n",
    "    \n",
    "    obs = env.observe()\n",
    "    \n",
    "    for _ in range(maxstep):\n",
    "        valid_actions = env.valid_actions()\n",
    "        if not valid_actions: break\n",
    "        counter = counter + 1\n",
    "        \n",
    "        if np.random.rand() < epsilon:\n",
    "            action = random.choice(valid_actions)\n",
    "        else:\n",
    "            values = Qprincipal.compute_Qvalues(obs)\n",
    "            action = np.argmax(values)\n",
    "        \n",
    "\n",
    "\n",
    "        obs_, reward, done = env.act(action)\n",
    "        rewardsum += reward\n",
    "        \n",
    "        Q_old = Qprincipal.compute_Qvalues(obs)\n",
    "        #Implement buffer replay to store memory\n",
    "        experience = (obs, action, reward, obs_, Q_old)\n",
    "        buffer.append(experience)\n",
    "        buffer.pop()\n",
    "        \n",
    "            \n",
    "        if counter>initialsize and counter%5 == 0:\n",
    "            #Sample from stored memory\n",
    "            Samples = buffer.sample(batchsize)\n",
    "\n",
    "            #Conpute target_i\n",
    "            states = []\n",
    "            actions = []\n",
    "            targets = []\n",
    "            Q_olds = []\n",
    "            for i in range(len(Samples)):\n",
    "                s_current, action, r, s_next, Q_old = Samples[i]\n",
    "                Q_target = Qtarget.compute_Qvalues(s_next)\n",
    "                states.extend(s_current)\n",
    "                actions.append(action)\n",
    "                target = r + gamma * np.max(Q_target)\n",
    "                targets.append(target)\n",
    "                Q_olds.append(Q_old[0])\n",
    "\n",
    "            #Compute empirical loss, update theta\n",
    "            loss = Qprincipal.train(states, actions, targets, Q_olds)\n",
    "#             print(loss)\n",
    "            \n",
    "        #Update target network\n",
    "        if counter % tau == 0:\n",
    "            sess.run(update)\n",
    "        if done != 'not_over':\n",
    "            break\n",
    "        #Swap observation\n",
    "        obs = obs_\n",
    "    reward_record.append(rewardsum)\n",
    "    \n",
    "    print('Finished {} episode.Reward ={}.'.format(e+1,rewardsum))\n",
    "    if e % 5 == 0:\n",
    "        env.reset(rat_cell)\n",
    "        done = 'not_over'\n",
    "        \n",
    "        obs = env.observe()\n",
    "        rewardsum = 0\n",
    "        for _ in range(50):\n",
    "            values = Qprincipal.compute_Qvalues(obs)\n",
    "            action = np.argmax(values)\n",
    "            obs_, reward, done = env.act(action)\n",
    "            rewardsum += reward\n",
    "            if done == 'win':\n",
    "                break\n",
    "            obs = obs_\n",
    "        evaluation_record.append(rewardsum)\n",
    "        show(env, file_name = 'div_DQN_eval/div_Maze'+str(e+1))\n",
    "        with open('div_DQN_rewardsEval.dat', 'a') as eval_reward_file:\n",
    "             print(np.mean(evaluation_record[:-10]), file=eval_reward_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conge\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\conge\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    with open('div_DQN_rewardsEval_1.dat', 'a') as eval_reward_file:\n",
    "        if i < 10:\n",
    "            print(np.mean(evaluation_record[:i]), file=eval_reward_file)\n",
    "        else:\n",
    "            print(np.mean(evaluation_record[(i-10):i]), file=eval_reward_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wzg: create a S*A matrix at the initialization step.  In each sample process, only to replace "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
