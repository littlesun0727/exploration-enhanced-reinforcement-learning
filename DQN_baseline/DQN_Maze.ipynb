{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conge\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maze is a 2d Numpy array of floats between 0.0 to 1.0\n",
    "# 1.0 corresponds to a free cell, and 0.0 an occupied cell\n",
    "# rat = (row, col) initial rat position (defaults to (0,0))\n",
    "\n",
    "class Qmaze(object):\n",
    "    def __init__(self, maze, rat=(0,0)):\n",
    "        self._maze = np.array(maze)\n",
    "        nrows, ncols = self._maze.shape\n",
    "        self.target = (nrows-1, ncols-1)   # target cell where the \"cheese\" is\n",
    "        self.free_cells = [(r,c) for r in range(nrows) for c in range(ncols) if self._maze[r,c] == 1.0]\n",
    "        self.free_cells.remove(self.target)\n",
    "        if self._maze[self.target] == 0.0:\n",
    "            raise Exception(\"Invalid maze: target cell cannot be blocked!\")\n",
    "        if not rat in self.free_cells:\n",
    "            raise Exception(\"Invalid Rat Location: must sit on a free cell\")\n",
    "        self.reset(rat)\n",
    "\n",
    "    def reset(self, rat):\n",
    "        self.rat = rat\n",
    "        self.maze = np.copy(self._maze)\n",
    "        nrows, ncols = self.maze.shape\n",
    "        row, col = rat\n",
    "        self.maze[row, col] = rat_mark\n",
    "        self.state = (row, col, 'start')\n",
    "        self.min_reward = -0.5 * self.maze.size\n",
    "        self.total_reward = 0\n",
    "        self.visited = set()\n",
    "\n",
    "    def update_state(self, action):\n",
    "        nrows, ncols = self.maze.shape\n",
    "        nrow, ncol, nmode = rat_row, rat_col, mode = self.state\n",
    "\n",
    "        if self.maze[rat_row, rat_col] > 0.0:\n",
    "            self.visited.add((rat_row, rat_col))  # mark visited cell\n",
    "\n",
    "        valid_actions = self.valid_actions()\n",
    "                \n",
    "        if not valid_actions:\n",
    "            nmode = 'blocked'\n",
    "        elif action in valid_actions:\n",
    "            nmode = 'valid'\n",
    "            if action == LEFT:\n",
    "                ncol -= 1\n",
    "            elif action == UP:\n",
    "                nrow -= 1\n",
    "            if action == RIGHT:\n",
    "                ncol += 1\n",
    "            elif action == DOWN:\n",
    "                nrow += 1\n",
    "        else:                  # invalid action, no change in rat position\n",
    "            mode = 'invalid'\n",
    "\n",
    "        # new state\n",
    "        self.state = (nrow, ncol, nmode)\n",
    "\n",
    "    def get_reward(self):\n",
    "        rat_row, rat_col, mode = self.state\n",
    "        nrows, ncols = self.maze.shape\n",
    "        if rat_row == nrows-1 and rat_col == ncols-1:\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    def act(self, action):\n",
    "        self.update_state(action)\n",
    "        reward = self.get_reward()\n",
    "        self.total_reward += reward\n",
    "        status = self.game_status()\n",
    "        envstate = self.observe()\n",
    "        return envstate, reward, status\n",
    "\n",
    "    def observe(self):\n",
    "        canvas = self.draw_env()\n",
    "        envstate = canvas.reshape((1, -1))\n",
    "        return envstate\n",
    "\n",
    "    def draw_env(self):\n",
    "        canvas = np.copy(self.maze)\n",
    "        nrows, ncols = self.maze.shape\n",
    "        # clear all visual marks\n",
    "        for r in range(nrows):\n",
    "            for c in range(ncols):\n",
    "                if canvas[r,c] > 0.0:\n",
    "                    canvas[r,c] = 1.0\n",
    "        # draw the rat\n",
    "        row, col, valid = self.state\n",
    "        canvas[row, col] = rat_mark\n",
    "        return canvas\n",
    "\n",
    "    def game_status(self):\n",
    "        rat_row, rat_col, mode = self.state\n",
    "        nrows, ncols = self.maze.shape\n",
    "        if rat_row == nrows-1 and rat_col == ncols-1:\n",
    "            return 'win'\n",
    "\n",
    "        return 'not_over'\n",
    "\n",
    "    def valid_actions(self, cell=None):\n",
    "        if cell is None:\n",
    "            row, col, mode = self.state\n",
    "        else:\n",
    "            row, col = cell\n",
    "        actions = [0, 1, 2, 3]\n",
    "        nrows, ncols = self.maze.shape\n",
    "        if row == 0:\n",
    "            actions.remove(1)\n",
    "        elif row == nrows-1:\n",
    "            actions.remove(3)\n",
    "\n",
    "        if col == 0:\n",
    "            actions.remove(0)\n",
    "        elif col == ncols-1:\n",
    "            actions.remove(2)\n",
    "\n",
    "        if row>0 and self.maze[row-1,col] == 0.0:\n",
    "            actions.remove(1)\n",
    "        if row<nrows-1 and self.maze[row+1,col] == 0.0:\n",
    "            actions.remove(3)\n",
    "\n",
    "        if col>0 and self.maze[row,col-1] == 0.0:\n",
    "            actions.remove(0)\n",
    "        if col<ncols-1 and self.maze[row,col+1] == 0.0:\n",
    "            actions.remove(2)\n",
    "\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural net Q_\\theta(s,a) as a class\n",
    "\n",
    "class Qfunction(object):\n",
    "    \n",
    "    def __init__(self, obssize, actsize, sess, optimizer):\n",
    "        \"\"\"\n",
    "        obssize: dimension of state space\n",
    "        actsize: dimension of action space\n",
    "        sess: sess to execute this Qfunction\n",
    "        optimizer: \n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        # build the prediction graph\n",
    "        state = tf.placeholder(tf.float32, [None, obssize])\n",
    "        \n",
    "        #Construct a FNN with 1 hidden layer\n",
    "        Layer1_nodes = 24\n",
    "        W1 = tf.get_variable('W1',[obssize, Layer1_nodes],initializer = tf.truncated_normal_initializer(stddev=.1))\n",
    "        b1 = tf.get_variable('b1',[Layer1_nodes],initializer = tf.truncated_normal_initializer(stddev=.1))\n",
    "        h1 = tf.nn.relu(tf.matmul(state,W1) + b1)\n",
    "        \n",
    "#         Layer2_nodes = 24\n",
    "#         W2 = tf.get_variable('W2',[Layer1_nodes, Layer2_nodes],initializer = tf.truncated_normal_initializer(stddev=.1))\n",
    "#         b2 = tf.get_variable('b2',[Layer2_nodes],initializer = tf.truncated_normal_initializer(stddev=.1))\n",
    "#         h2 = tf.nn.relu(tf.matmul(h1, W2) + b2)\n",
    "        \n",
    "        W2 = tf.get_variable('W2',[Layer1_nodes, actsize],initializer = tf.truncated_normal_initializer(stddev=.1))\n",
    "        b2 = tf.get_variable('b2',[actsize],initializer = tf.truncated_normal_initializer(stddev=.1))\n",
    "        h2 = tf.matmul(h1, W2) + b2        \n",
    "        \n",
    "        Qvalues = h2  # make sure it has size [None, actsize]\n",
    "        \n",
    "        # build the targets and actions\n",
    "        # targets represent the terms E[r+gamma Q] in Bellman equations\n",
    "        # actions represent a_t\n",
    "        targets = tf.placeholder(tf.float32, [None])\n",
    "        actions = tf.placeholder(tf.int32, [None])\n",
    "        actions_one_hot = tf.one_hot(actions, actsize)\n",
    "        Qpreds = tf.reduce_sum(tf.multiply(h2, actions_one_hot), axis=1) # make sure it has size [None]\n",
    "        loss = tf.reduce_mean(tf.square(Qpreds - targets))\n",
    "\n",
    "        # optimization\n",
    "        self.train_op = optimizer.minimize(loss)\n",
    "        \n",
    "        # some bookkeeping\n",
    "        self.Qvalues = Qvalues\n",
    "        self.state = state\n",
    "        self.actions = actions\n",
    "        self.targets = targets\n",
    "        self.loss = loss\n",
    "        self.sess = sess\n",
    "    \n",
    "    def compute_Qvalues(self, states):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return self.sess.run(self.Qvalues, feed_dict={self.state: states})\n",
    "\n",
    "    def train(self, states, actions, targets):\n",
    "        \"\"\"\n",
    "        states: numpy array as input to compute loss (s)\n",
    "        actions: numpy array as input to compute loss (a)\n",
    "        targets: numpy array as input to compute loss (Q targets)\n",
    "        \"\"\"\n",
    "        return self.sess.run([self.loss,self.train_op], feed_dict={self.state:states, self.actions:actions, self.targets:targets})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement replay buffer\n",
    "class ReplayBuffer(object):\n",
    "    \n",
    "    def __init__(self, maxlength):\n",
    "        \"\"\"\n",
    "        maxlength: max number of tuples to store in the buffer\n",
    "        if there are more tuples than maxlength, pop out the oldest tuples\n",
    "        \"\"\"\n",
    "        self.buffer = deque()\n",
    "        self.number = 0\n",
    "        self.maxlength = maxlength\n",
    "    \n",
    "    def append(self, experience):\n",
    "        \"\"\"\n",
    "        this function implements appending new experience tuple\n",
    "        experience: a tuple of the form (s,a,r,s^\\prime)\n",
    "        \"\"\"\n",
    "        self.buffer.append(experience)\n",
    "        self.number += 1\n",
    "        \n",
    "    def pop(self):\n",
    "        \"\"\"\n",
    "        pop out the oldest tuples if self.number > self.maxlength\n",
    "        \"\"\"\n",
    "        while self.number > self.maxlength:\n",
    "            self.buffer.popleft()\n",
    "            self.number -= 1\n",
    "    \n",
    "    def sample(self, batchsize):\n",
    "        \"\"\"\n",
    "        this function samples 'batchsize' experience tuples\n",
    "        batchsize: size of the minibatch to be sampled\n",
    "        return: a list of tuples of form (s,a,r,s^\\prime)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        if batchsize < self.number:\n",
    "            minibatch = random.sample(self.buffer, batchsize) \n",
    "        else:\n",
    "            minibatch = random.sample(self.buffer, self.number) \n",
    "        return minibatch  # need implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_target_update(from_scope, to_scope):\n",
    "    from_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=from_scope)\n",
    "    to_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=to_scope)\n",
    "    op = []\n",
    "    for v1, v2 in zip(from_vars, to_vars):\n",
    "        op.append(v2.assign(0.2*v1+0.8*v2))\n",
    "    return op    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maze = np.array([\n",
    "#     [ 1.,  0.,  1.,  1.,  1.,  1.,  1.],\n",
    "#     [ 1.,  1.,  1.,  0.,  0.,  1.,  0.],\n",
    "#     [ 0.,  0.,  0.,  1.,  1.,  1.,  0.],\n",
    "#     [ 1.,  1.,  1.,  1.,  0.,  0.,  1.],\n",
    "#     [ 1.,  0.,  0.,  0.,  1.,  1.,  1.],\n",
    "#     [ 1.,  0.,  1.,  1.,  1.,  1.,  1.],\n",
    "#     [ 1.,  1.,  1.,  0.,  1.,  1.,  1.]\n",
    "# ])\n",
    "maze = np.array([\n",
    "     [ 1.,  0.,  1.,  1.,  1.,  0.,  1.],\n",
    "     [ 1.,  1.,  1.,  1.,  0.,  1.,  1.],\n",
    "     [ 1.,  1.,  1.,  0.,  1.,  1.,  1.],\n",
    "     [ 0.,  1.,  1.,  1.,  1.,  1.,  0.],\n",
    "     [ 1.,  1.,  0.,  0.,  1.,  1.,  1.],\n",
    "     [ 1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "     [ 1.,  1.,  1.,  1.,  0.,  1.,  1.]\n",
    "])\n",
    "visited_mark = 0.8  # Cells visited by the rat will be painted by gray 0.8\n",
    "rat_mark = 0.5      # The current rat cell will be painteg by gray 0.5\n",
    "LEFT = 0\n",
    "UP = 1\n",
    "RIGHT = 2\n",
    "DOWN = 3\n",
    "\n",
    "# Actions dictionary\n",
    "actions_dict = {\n",
    "    LEFT: 'left',\n",
    "    UP: 'up',\n",
    "    RIGHT: 'right',\n",
    "    DOWN: 'down',\n",
    "}\n",
    "\n",
    "num_actions = len(actions_dict)\n",
    "\n",
    "rat_cell = (0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(qmaze, file_name = 'Maze'):\n",
    "    plt.grid('on')\n",
    "    nrows, ncols = qmaze.maze.shape\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks(np.arange(0.5, nrows, 1))\n",
    "    ax.set_yticks(np.arange(0.5, ncols, 1))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    canvas = np.copy(qmaze.maze)\n",
    "    for row,col in qmaze.visited:\n",
    "        canvas[row,col] = 0.6\n",
    "    rat_row, rat_col, _ = qmaze.state\n",
    "    canvas[rat_row, rat_col] = 0.3   # rat cell\n",
    "    canvas[nrows-1, ncols-1] = 0.9 # cheese cell\n",
    "    img = plt.imshow(canvas, interpolation='none', cmap='gray')\n",
    "    plt.imshow(canvas, interpolation='none', cmap='gray')\n",
    "    plt.savefig(file_name)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conge\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:424: MatplotlibDeprecationWarning: \n",
      "Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warn_deprecated(\"2.2\", \"Passing one of 'on', 'true', 'off', 'false' as a \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21194f742b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = Qmaze(maze)\n",
    "show(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 1 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conge\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:424: MatplotlibDeprecationWarning: \n",
      "Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warn_deprecated(\"2.2\", \"Passing one of 'on', 'true', 'off', 'false' as a \"\n",
      "C:\\Users\\conge\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\conge\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 2 episode.rewardsum=0.\n",
      "Finished 3 episode.rewardsum=0.\n",
      "Finished 4 episode.rewardsum=0.\n",
      "Finished 5 episode.rewardsum=0.\n",
      "Finished 6 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 7 episode.rewardsum=0.\n",
      "Finished 8 episode.rewardsum=0.\n",
      "Finished 9 episode.rewardsum=1.\n",
      "Finished 10 episode.rewardsum=0.\n",
      "Finished 11 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 12 episode.rewardsum=0.\n",
      "Finished 13 episode.rewardsum=0.\n",
      "Finished 14 episode.rewardsum=0.\n",
      "Finished 15 episode.rewardsum=0.\n",
      "Finished 16 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 17 episode.rewardsum=0.\n",
      "Finished 18 episode.rewardsum=1.\n",
      "Finished 19 episode.rewardsum=1.\n",
      "Finished 20 episode.rewardsum=0.\n",
      "Finished 21 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 22 episode.rewardsum=1.\n",
      "Finished 23 episode.rewardsum=0.\n",
      "Finished 24 episode.rewardsum=0.\n",
      "Finished 25 episode.rewardsum=0.\n",
      "Finished 26 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 27 episode.rewardsum=0.\n",
      "Finished 28 episode.rewardsum=0.\n",
      "Finished 29 episode.rewardsum=0.\n",
      "Finished 30 episode.rewardsum=0.\n",
      "Finished 31 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 32 episode.rewardsum=0.\n",
      "Finished 33 episode.rewardsum=1.\n",
      "Finished 34 episode.rewardsum=0.\n",
      "Finished 35 episode.rewardsum=0.\n",
      "Finished 36 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 37 episode.rewardsum=0.\n",
      "Finished 38 episode.rewardsum=0.\n",
      "Finished 39 episode.rewardsum=0.\n",
      "Finished 40 episode.rewardsum=1.\n",
      "Finished 41 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 42 episode.rewardsum=0.\n",
      "Finished 43 episode.rewardsum=0.\n",
      "Finished 44 episode.rewardsum=0.\n",
      "Finished 45 episode.rewardsum=1.\n",
      "Finished 46 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 47 episode.rewardsum=0.\n",
      "Finished 48 episode.rewardsum=0.\n",
      "Finished 49 episode.rewardsum=1.\n",
      "Finished 50 episode.rewardsum=0.\n",
      "Finished 51 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 52 episode.rewardsum=1.\n",
      "Finished 53 episode.rewardsum=0.\n",
      "Finished 54 episode.rewardsum=0.\n",
      "Finished 55 episode.rewardsum=1.\n",
      "Finished 56 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 57 episode.rewardsum=0.\n",
      "Finished 58 episode.rewardsum=0.\n",
      "Finished 59 episode.rewardsum=0.\n",
      "Finished 60 episode.rewardsum=0.\n",
      "Finished 61 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 62 episode.rewardsum=0.\n",
      "Finished 63 episode.rewardsum=1.\n",
      "Finished 64 episode.rewardsum=0.\n",
      "Finished 65 episode.rewardsum=1.\n",
      "Finished 66 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 67 episode.rewardsum=1.\n",
      "Finished 68 episode.rewardsum=1.\n",
      "Finished 69 episode.rewardsum=1.\n",
      "Finished 70 episode.rewardsum=0.\n",
      "Finished 71 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 72 episode.rewardsum=0.\n",
      "Finished 73 episode.rewardsum=0.\n",
      "Finished 74 episode.rewardsum=1.\n",
      "Finished 75 episode.rewardsum=0.\n",
      "Finished 76 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 77 episode.rewardsum=1.\n",
      "Finished 78 episode.rewardsum=1.\n",
      "Finished 79 episode.rewardsum=1.\n",
      "Finished 80 episode.rewardsum=0.\n",
      "Finished 81 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 82 episode.rewardsum=0.\n",
      "Finished 83 episode.rewardsum=0.\n",
      "Finished 84 episode.rewardsum=0.\n",
      "Finished 85 episode.rewardsum=1.\n",
      "Finished 86 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 87 episode.rewardsum=0.\n",
      "Finished 88 episode.rewardsum=1.\n",
      "Finished 89 episode.rewardsum=1.\n",
      "Finished 90 episode.rewardsum=1.\n",
      "Finished 91 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 92 episode.rewardsum=1.\n",
      "Finished 93 episode.rewardsum=0.\n",
      "Finished 94 episode.rewardsum=0.\n",
      "Finished 95 episode.rewardsum=1.\n",
      "Finished 96 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 97 episode.rewardsum=1.\n",
      "Finished 98 episode.rewardsum=1.\n",
      "Finished 99 episode.rewardsum=0.\n",
      "Finished 100 episode.rewardsum=1.\n",
      "Finished 101 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 102 episode.rewardsum=1.\n",
      "Finished 103 episode.rewardsum=0.\n",
      "Finished 104 episode.rewardsum=1.\n",
      "Finished 105 episode.rewardsum=0.\n",
      "Finished 106 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 107 episode.rewardsum=0.\n",
      "Finished 108 episode.rewardsum=1.\n",
      "Finished 109 episode.rewardsum=1.\n",
      "Finished 110 episode.rewardsum=1.\n",
      "Finished 111 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 112 episode.rewardsum=0.\n",
      "Finished 113 episode.rewardsum=0.\n",
      "Finished 114 episode.rewardsum=1.\n",
      "Finished 115 episode.rewardsum=0.\n",
      "Finished 116 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 117 episode.rewardsum=0.\n",
      "Finished 118 episode.rewardsum=1.\n",
      "Finished 119 episode.rewardsum=0.\n",
      "Finished 120 episode.rewardsum=0.\n",
      "Finished 121 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 122 episode.rewardsum=0.\n",
      "Finished 123 episode.rewardsum=1.\n",
      "Finished 124 episode.rewardsum=0.\n",
      "Finished 125 episode.rewardsum=1.\n",
      "Finished 126 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 127 episode.rewardsum=0.\n",
      "Finished 128 episode.rewardsum=0.\n",
      "Finished 129 episode.rewardsum=0.\n",
      "Finished 130 episode.rewardsum=0.\n",
      "Finished 131 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 132 episode.rewardsum=0.\n",
      "Finished 133 episode.rewardsum=0.\n",
      "Finished 134 episode.rewardsum=0.\n",
      "Finished 135 episode.rewardsum=1.\n",
      "Finished 136 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 137 episode.rewardsum=0.\n",
      "Finished 138 episode.rewardsum=0.\n",
      "Finished 139 episode.rewardsum=1.\n",
      "Finished 140 episode.rewardsum=0.\n",
      "Finished 141 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 142 episode.rewardsum=1.\n",
      "Finished 143 episode.rewardsum=1.\n",
      "Finished 144 episode.rewardsum=1.\n",
      "Finished 145 episode.rewardsum=0.\n",
      "Finished 146 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 147 episode.rewardsum=1.\n",
      "Finished 148 episode.rewardsum=1.\n",
      "Finished 149 episode.rewardsum=0.\n",
      "Finished 150 episode.rewardsum=0.\n",
      "Finished 151 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 152 episode.rewardsum=1.\n",
      "Finished 153 episode.rewardsum=0.\n",
      "Finished 154 episode.rewardsum=1.\n",
      "Finished 155 episode.rewardsum=0.\n",
      "Finished 156 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 157 episode.rewardsum=1.\n",
      "Finished 158 episode.rewardsum=1.\n",
      "Finished 159 episode.rewardsum=1.\n",
      "Finished 160 episode.rewardsum=0.\n",
      "Finished 161 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 162 episode.rewardsum=1.\n",
      "Finished 163 episode.rewardsum=1.\n",
      "Finished 164 episode.rewardsum=1.\n",
      "Finished 165 episode.rewardsum=1.\n",
      "Finished 166 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 167 episode.rewardsum=1.\n",
      "Finished 168 episode.rewardsum=0.\n",
      "Finished 169 episode.rewardsum=1.\n",
      "Finished 170 episode.rewardsum=1.\n",
      "Finished 171 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 172 episode.rewardsum=1.\n",
      "Finished 173 episode.rewardsum=1.\n",
      "Finished 174 episode.rewardsum=1.\n",
      "Finished 175 episode.rewardsum=1.\n",
      "Finished 176 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 177 episode.rewardsum=1.\n",
      "Finished 178 episode.rewardsum=1.\n",
      "Finished 179 episode.rewardsum=0.\n",
      "Finished 180 episode.rewardsum=1.\n",
      "Finished 181 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 182 episode.rewardsum=0.\n",
      "Finished 183 episode.rewardsum=0.\n",
      "Finished 184 episode.rewardsum=0.\n",
      "Finished 185 episode.rewardsum=1.\n",
      "Finished 186 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 187 episode.rewardsum=1.\n",
      "Finished 188 episode.rewardsum=1.\n",
      "Finished 189 episode.rewardsum=1.\n",
      "Finished 190 episode.rewardsum=1.\n",
      "Finished 191 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 192 episode.rewardsum=0.\n",
      "Finished 193 episode.rewardsum=0.\n",
      "Finished 194 episode.rewardsum=1.\n",
      "Finished 195 episode.rewardsum=0.\n",
      "Finished 196 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 197 episode.rewardsum=1.\n",
      "Finished 198 episode.rewardsum=1.\n",
      "Finished 199 episode.rewardsum=0.\n",
      "Finished 200 episode.rewardsum=1.\n",
      "Finished 201 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 202 episode.rewardsum=1.\n",
      "Finished 203 episode.rewardsum=0.\n",
      "Finished 204 episode.rewardsum=1.\n",
      "Finished 205 episode.rewardsum=0.\n",
      "Finished 206 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 207 episode.rewardsum=0.\n",
      "Finished 208 episode.rewardsum=0.\n",
      "Finished 209 episode.rewardsum=1.\n",
      "Finished 210 episode.rewardsum=1.\n",
      "Finished 211 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 212 episode.rewardsum=1.\n",
      "Finished 213 episode.rewardsum=0.\n",
      "Finished 214 episode.rewardsum=1.\n",
      "Finished 215 episode.rewardsum=1.\n",
      "Finished 216 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 217 episode.rewardsum=1.\n",
      "Finished 218 episode.rewardsum=1.\n",
      "Finished 219 episode.rewardsum=1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 220 episode.rewardsum=1.\n",
      "Finished 221 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 222 episode.rewardsum=1.\n",
      "Finished 223 episode.rewardsum=1.\n",
      "Finished 224 episode.rewardsum=1.\n",
      "Finished 225 episode.rewardsum=0.\n",
      "Finished 226 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 227 episode.rewardsum=1.\n",
      "Finished 228 episode.rewardsum=1.\n",
      "Finished 229 episode.rewardsum=1.\n",
      "Finished 230 episode.rewardsum=1.\n",
      "Finished 231 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 232 episode.rewardsum=1.\n",
      "Finished 233 episode.rewardsum=1.\n",
      "Finished 234 episode.rewardsum=0.\n",
      "Finished 235 episode.rewardsum=1.\n",
      "Finished 236 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 237 episode.rewardsum=1.\n",
      "Finished 238 episode.rewardsum=1.\n",
      "Finished 239 episode.rewardsum=1.\n",
      "Finished 240 episode.rewardsum=0.\n",
      "Finished 241 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 242 episode.rewardsum=1.\n",
      "Finished 243 episode.rewardsum=1.\n",
      "Finished 244 episode.rewardsum=1.\n",
      "Finished 245 episode.rewardsum=1.\n",
      "Finished 246 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 247 episode.rewardsum=1.\n",
      "Finished 248 episode.rewardsum=1.\n",
      "Finished 249 episode.rewardsum=1.\n",
      "Finished 250 episode.rewardsum=0.\n",
      "Finished 251 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 252 episode.rewardsum=1.\n",
      "Finished 253 episode.rewardsum=1.\n",
      "Finished 254 episode.rewardsum=1.\n",
      "Finished 255 episode.rewardsum=1.\n",
      "Finished 256 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 257 episode.rewardsum=1.\n",
      "Finished 258 episode.rewardsum=1.\n",
      "Finished 259 episode.rewardsum=1.\n",
      "Finished 260 episode.rewardsum=1.\n",
      "Finished 261 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 262 episode.rewardsum=1.\n",
      "Finished 263 episode.rewardsum=1.\n",
      "Finished 264 episode.rewardsum=1.\n",
      "Finished 265 episode.rewardsum=1.\n",
      "Finished 266 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 267 episode.rewardsum=1.\n",
      "Finished 268 episode.rewardsum=1.\n",
      "Finished 269 episode.rewardsum=1.\n",
      "Finished 270 episode.rewardsum=1.\n",
      "Finished 271 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 272 episode.rewardsum=1.\n",
      "Finished 273 episode.rewardsum=1.\n",
      "Finished 274 episode.rewardsum=1.\n",
      "Finished 275 episode.rewardsum=0.\n",
      "Finished 276 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 277 episode.rewardsum=1.\n",
      "Finished 278 episode.rewardsum=1.\n",
      "Finished 279 episode.rewardsum=1.\n",
      "Finished 280 episode.rewardsum=1.\n",
      "Finished 281 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 282 episode.rewardsum=1.\n",
      "Finished 283 episode.rewardsum=1.\n",
      "Finished 284 episode.rewardsum=1.\n",
      "Finished 285 episode.rewardsum=1.\n",
      "Finished 286 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 287 episode.rewardsum=1.\n",
      "Finished 288 episode.rewardsum=1.\n",
      "Finished 289 episode.rewardsum=1.\n",
      "Finished 290 episode.rewardsum=1.\n",
      "Finished 291 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 292 episode.rewardsum=1.\n",
      "Finished 293 episode.rewardsum=0.\n",
      "Finished 294 episode.rewardsum=0.\n",
      "Finished 295 episode.rewardsum=1.\n",
      "Finished 296 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 297 episode.rewardsum=1.\n",
      "Finished 298 episode.rewardsum=1.\n",
      "Finished 299 episode.rewardsum=1.\n",
      "Finished 300 episode.rewardsum=1.\n",
      "Finished 301 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 302 episode.rewardsum=1.\n",
      "Finished 303 episode.rewardsum=1.\n",
      "Finished 304 episode.rewardsum=1.\n",
      "Finished 305 episode.rewardsum=1.\n",
      "Finished 306 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 307 episode.rewardsum=1.\n",
      "Finished 308 episode.rewardsum=1.\n",
      "Finished 309 episode.rewardsum=1.\n",
      "Finished 310 episode.rewardsum=1.\n",
      "Finished 311 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 312 episode.rewardsum=1.\n",
      "Finished 313 episode.rewardsum=1.\n",
      "Finished 314 episode.rewardsum=1.\n",
      "Finished 315 episode.rewardsum=1.\n",
      "Finished 316 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 317 episode.rewardsum=1.\n",
      "Finished 318 episode.rewardsum=1.\n",
      "Finished 319 episode.rewardsum=1.\n",
      "Finished 320 episode.rewardsum=1.\n",
      "Finished 321 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 322 episode.rewardsum=1.\n",
      "Finished 323 episode.rewardsum=1.\n",
      "Finished 324 episode.rewardsum=1.\n",
      "Finished 325 episode.rewardsum=1.\n",
      "Finished 326 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 327 episode.rewardsum=1.\n",
      "Finished 328 episode.rewardsum=1.\n",
      "Finished 329 episode.rewardsum=1.\n",
      "Finished 330 episode.rewardsum=1.\n",
      "Finished 331 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 332 episode.rewardsum=1.\n",
      "Finished 333 episode.rewardsum=1.\n",
      "Finished 334 episode.rewardsum=1.\n",
      "Finished 335 episode.rewardsum=1.\n",
      "Finished 336 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 337 episode.rewardsum=1.\n",
      "Finished 338 episode.rewardsum=1.\n",
      "Finished 339 episode.rewardsum=1.\n",
      "Finished 340 episode.rewardsum=1.\n",
      "Finished 341 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 342 episode.rewardsum=1.\n",
      "Finished 343 episode.rewardsum=1.\n",
      "Finished 344 episode.rewardsum=1.\n",
      "Finished 345 episode.rewardsum=1.\n",
      "Finished 346 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 347 episode.rewardsum=1.\n",
      "Finished 348 episode.rewardsum=1.\n",
      "Finished 349 episode.rewardsum=1.\n",
      "Finished 350 episode.rewardsum=1.\n",
      "Finished 351 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 352 episode.rewardsum=1.\n",
      "Finished 353 episode.rewardsum=1.\n",
      "Finished 354 episode.rewardsum=1.\n",
      "Finished 355 episode.rewardsum=1.\n",
      "Finished 356 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 357 episode.rewardsum=0.\n",
      "Finished 358 episode.rewardsum=1.\n",
      "Finished 359 episode.rewardsum=1.\n",
      "Finished 360 episode.rewardsum=1.\n",
      "Finished 361 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 362 episode.rewardsum=1.\n",
      "Finished 363 episode.rewardsum=1.\n",
      "Finished 364 episode.rewardsum=0.\n",
      "Finished 365 episode.rewardsum=1.\n",
      "Finished 366 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 367 episode.rewardsum=1.\n",
      "Finished 368 episode.rewardsum=1.\n",
      "Finished 369 episode.rewardsum=1.\n",
      "Finished 370 episode.rewardsum=1.\n",
      "Finished 371 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 372 episode.rewardsum=1.\n",
      "Finished 373 episode.rewardsum=1.\n",
      "Finished 374 episode.rewardsum=1.\n",
      "Finished 375 episode.rewardsum=1.\n",
      "Finished 376 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 377 episode.rewardsum=1.\n",
      "Finished 378 episode.rewardsum=1.\n",
      "Finished 379 episode.rewardsum=1.\n",
      "Finished 380 episode.rewardsum=1.\n",
      "Finished 381 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 382 episode.rewardsum=1.\n",
      "Finished 383 episode.rewardsum=1.\n",
      "Finished 384 episode.rewardsum=1.\n",
      "Finished 385 episode.rewardsum=1.\n",
      "Finished 386 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 387 episode.rewardsum=1.\n",
      "Finished 388 episode.rewardsum=1.\n",
      "Finished 389 episode.rewardsum=1.\n",
      "Finished 390 episode.rewardsum=1.\n",
      "Finished 391 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 392 episode.rewardsum=1.\n",
      "Finished 393 episode.rewardsum=1.\n",
      "Finished 394 episode.rewardsum=1.\n",
      "Finished 395 episode.rewardsum=1.\n",
      "Finished 396 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 397 episode.rewardsum=1.\n",
      "Finished 398 episode.rewardsum=1.\n",
      "Finished 399 episode.rewardsum=1.\n",
      "Finished 400 episode.rewardsum=1.\n",
      "Finished 401 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 402 episode.rewardsum=1.\n",
      "Finished 403 episode.rewardsum=1.\n",
      "Finished 404 episode.rewardsum=1.\n",
      "Finished 405 episode.rewardsum=1.\n",
      "Finished 406 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 407 episode.rewardsum=1.\n",
      "Finished 408 episode.rewardsum=1.\n",
      "Finished 409 episode.rewardsum=1.\n",
      "Finished 410 episode.rewardsum=1.\n",
      "Finished 411 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 412 episode.rewardsum=1.\n",
      "Finished 413 episode.rewardsum=0.\n",
      "Finished 414 episode.rewardsum=1.\n",
      "Finished 415 episode.rewardsum=1.\n",
      "Finished 416 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 417 episode.rewardsum=1.\n",
      "Finished 418 episode.rewardsum=1.\n",
      "Finished 419 episode.rewardsum=1.\n",
      "Finished 420 episode.rewardsum=1.\n",
      "Finished 421 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 422 episode.rewardsum=1.\n",
      "Finished 423 episode.rewardsum=1.\n",
      "Finished 424 episode.rewardsum=1.\n",
      "Finished 425 episode.rewardsum=1.\n",
      "Finished 426 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 427 episode.rewardsum=1.\n",
      "Finished 428 episode.rewardsum=1.\n",
      "Finished 429 episode.rewardsum=1.\n",
      "Finished 430 episode.rewardsum=1.\n",
      "Finished 431 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 432 episode.rewardsum=1.\n",
      "Finished 433 episode.rewardsum=1.\n",
      "Finished 434 episode.rewardsum=1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 435 episode.rewardsum=1.\n",
      "Finished 436 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 437 episode.rewardsum=1.\n",
      "Finished 438 episode.rewardsum=1.\n",
      "Finished 439 episode.rewardsum=1.\n",
      "Finished 440 episode.rewardsum=1.\n",
      "Finished 441 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 442 episode.rewardsum=1.\n",
      "Finished 443 episode.rewardsum=1.\n",
      "Finished 444 episode.rewardsum=1.\n",
      "Finished 445 episode.rewardsum=1.\n",
      "Finished 446 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 447 episode.rewardsum=1.\n",
      "Finished 448 episode.rewardsum=1.\n",
      "Finished 449 episode.rewardsum=1.\n",
      "Finished 450 episode.rewardsum=1.\n",
      "Finished 451 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 452 episode.rewardsum=1.\n",
      "Finished 453 episode.rewardsum=1.\n",
      "Finished 454 episode.rewardsum=1.\n",
      "Finished 455 episode.rewardsum=1.\n",
      "Finished 456 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 457 episode.rewardsum=1.\n",
      "Finished 458 episode.rewardsum=1.\n",
      "Finished 459 episode.rewardsum=1.\n",
      "Finished 460 episode.rewardsum=1.\n",
      "Finished 461 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 462 episode.rewardsum=1.\n",
      "Finished 463 episode.rewardsum=1.\n",
      "Finished 464 episode.rewardsum=1.\n",
      "Finished 465 episode.rewardsum=1.\n",
      "Finished 466 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 467 episode.rewardsum=1.\n",
      "Finished 468 episode.rewardsum=1.\n",
      "Finished 469 episode.rewardsum=1.\n",
      "Finished 470 episode.rewardsum=1.\n",
      "Finished 471 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 472 episode.rewardsum=1.\n",
      "Finished 473 episode.rewardsum=1.\n",
      "Finished 474 episode.rewardsum=1.\n",
      "Finished 475 episode.rewardsum=1.\n",
      "Finished 476 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 477 episode.rewardsum=1.\n",
      "Finished 478 episode.rewardsum=1.\n",
      "Finished 479 episode.rewardsum=1.\n",
      "Finished 480 episode.rewardsum=1.\n",
      "Finished 481 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 482 episode.rewardsum=1.\n",
      "Finished 483 episode.rewardsum=0.\n",
      "Finished 484 episode.rewardsum=1.\n",
      "Finished 485 episode.rewardsum=1.\n",
      "Finished 486 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 487 episode.rewardsum=1.\n",
      "Finished 488 episode.rewardsum=1.\n",
      "Finished 489 episode.rewardsum=1.\n",
      "Finished 490 episode.rewardsum=1.\n",
      "Finished 491 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 492 episode.rewardsum=1.\n",
      "Finished 493 episode.rewardsum=1.\n",
      "Finished 494 episode.rewardsum=1.\n",
      "Finished 495 episode.rewardsum=1.\n",
      "Finished 496 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 497 episode.rewardsum=1.\n",
      "Finished 498 episode.rewardsum=1.\n",
      "Finished 499 episode.rewardsum=1.\n",
      "Finished 500 episode.rewardsum=1.\n",
      "Finished 501 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 502 episode.rewardsum=1.\n",
      "Finished 503 episode.rewardsum=1.\n",
      "Finished 504 episode.rewardsum=1.\n",
      "Finished 505 episode.rewardsum=1.\n",
      "Finished 506 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 507 episode.rewardsum=1.\n",
      "Finished 508 episode.rewardsum=1.\n",
      "Finished 509 episode.rewardsum=1.\n",
      "Finished 510 episode.rewardsum=1.\n",
      "Finished 511 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 512 episode.rewardsum=1.\n",
      "Finished 513 episode.rewardsum=1.\n",
      "Finished 514 episode.rewardsum=1.\n",
      "Finished 515 episode.rewardsum=1.\n",
      "Finished 516 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 517 episode.rewardsum=1.\n",
      "Finished 518 episode.rewardsum=1.\n",
      "Finished 519 episode.rewardsum=1.\n",
      "Finished 520 episode.rewardsum=1.\n",
      "Finished 521 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 522 episode.rewardsum=1.\n",
      "Finished 523 episode.rewardsum=1.\n",
      "Finished 524 episode.rewardsum=1.\n",
      "Finished 525 episode.rewardsum=1.\n",
      "Finished 526 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 527 episode.rewardsum=1.\n",
      "Finished 528 episode.rewardsum=1.\n",
      "Finished 529 episode.rewardsum=1.\n",
      "Finished 530 episode.rewardsum=1.\n",
      "Finished 531 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 532 episode.rewardsum=1.\n",
      "Finished 533 episode.rewardsum=1.\n",
      "Finished 534 episode.rewardsum=1.\n",
      "Finished 535 episode.rewardsum=1.\n",
      "Finished 536 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 537 episode.rewardsum=1.\n",
      "Finished 538 episode.rewardsum=1.\n",
      "Finished 539 episode.rewardsum=1.\n",
      "Finished 540 episode.rewardsum=1.\n",
      "Finished 541 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 542 episode.rewardsum=1.\n",
      "Finished 543 episode.rewardsum=1.\n",
      "Finished 544 episode.rewardsum=1.\n",
      "Finished 545 episode.rewardsum=1.\n",
      "Finished 546 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 547 episode.rewardsum=1.\n",
      "Finished 548 episode.rewardsum=1.\n",
      "Finished 549 episode.rewardsum=0.\n",
      "Finished 550 episode.rewardsum=1.\n",
      "Finished 551 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 552 episode.rewardsum=1.\n",
      "Finished 553 episode.rewardsum=1.\n",
      "Finished 554 episode.rewardsum=1.\n",
      "Finished 555 episode.rewardsum=1.\n",
      "Finished 556 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 557 episode.rewardsum=1.\n",
      "Finished 558 episode.rewardsum=1.\n",
      "Finished 559 episode.rewardsum=1.\n",
      "Finished 560 episode.rewardsum=1.\n",
      "Finished 561 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 562 episode.rewardsum=1.\n",
      "Finished 563 episode.rewardsum=1.\n",
      "Finished 564 episode.rewardsum=1.\n",
      "Finished 565 episode.rewardsum=1.\n",
      "Finished 566 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 567 episode.rewardsum=1.\n",
      "Finished 568 episode.rewardsum=1.\n",
      "Finished 569 episode.rewardsum=1.\n",
      "Finished 570 episode.rewardsum=1.\n",
      "Finished 571 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 572 episode.rewardsum=1.\n",
      "Finished 573 episode.rewardsum=1.\n",
      "Finished 574 episode.rewardsum=1.\n",
      "Finished 575 episode.rewardsum=1.\n",
      "Finished 576 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 577 episode.rewardsum=1.\n",
      "Finished 578 episode.rewardsum=1.\n",
      "Finished 579 episode.rewardsum=1.\n",
      "Finished 580 episode.rewardsum=1.\n",
      "Finished 581 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 582 episode.rewardsum=1.\n",
      "Finished 583 episode.rewardsum=1.\n",
      "Finished 584 episode.rewardsum=1.\n",
      "Finished 585 episode.rewardsum=1.\n",
      "Finished 586 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 587 episode.rewardsum=1.\n",
      "Finished 588 episode.rewardsum=1.\n",
      "Finished 589 episode.rewardsum=1.\n",
      "Finished 590 episode.rewardsum=1.\n",
      "Finished 591 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 592 episode.rewardsum=0.\n",
      "Finished 593 episode.rewardsum=1.\n",
      "Finished 594 episode.rewardsum=1.\n",
      "Finished 595 episode.rewardsum=1.\n",
      "Finished 596 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 597 episode.rewardsum=1.\n",
      "Finished 598 episode.rewardsum=1.\n",
      "Finished 599 episode.rewardsum=1.\n",
      "Finished 600 episode.rewardsum=1.\n",
      "Finished 601 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 602 episode.rewardsum=1.\n",
      "Finished 603 episode.rewardsum=1.\n",
      "Finished 604 episode.rewardsum=1.\n",
      "Finished 605 episode.rewardsum=1.\n",
      "Finished 606 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 607 episode.rewardsum=1.\n",
      "Finished 608 episode.rewardsum=1.\n",
      "Finished 609 episode.rewardsum=1.\n",
      "Finished 610 episode.rewardsum=1.\n",
      "Finished 611 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 612 episode.rewardsum=1.\n",
      "Finished 613 episode.rewardsum=1.\n",
      "Finished 614 episode.rewardsum=1.\n",
      "Finished 615 episode.rewardsum=1.\n",
      "Finished 616 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 617 episode.rewardsum=1.\n",
      "Finished 618 episode.rewardsum=1.\n",
      "Finished 619 episode.rewardsum=1.\n",
      "Finished 620 episode.rewardsum=1.\n",
      "Finished 621 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 622 episode.rewardsum=1.\n",
      "Finished 623 episode.rewardsum=1.\n",
      "Finished 624 episode.rewardsum=1.\n",
      "Finished 625 episode.rewardsum=1.\n",
      "Finished 626 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 627 episode.rewardsum=1.\n",
      "Finished 628 episode.rewardsum=1.\n",
      "Finished 629 episode.rewardsum=1.\n",
      "Finished 630 episode.rewardsum=1.\n",
      "Finished 631 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 632 episode.rewardsum=1.\n",
      "Finished 633 episode.rewardsum=1.\n",
      "Finished 634 episode.rewardsum=1.\n",
      "Finished 635 episode.rewardsum=1.\n",
      "Finished 636 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 637 episode.rewardsum=1.\n",
      "Finished 638 episode.rewardsum=1.\n",
      "Finished 639 episode.rewardsum=1.\n",
      "Finished 640 episode.rewardsum=1.\n",
      "Finished 641 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 642 episode.rewardsum=1.\n",
      "Finished 643 episode.rewardsum=1.\n",
      "Finished 644 episode.rewardsum=1.\n",
      "Finished 645 episode.rewardsum=1.\n",
      "Finished 646 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 647 episode.rewardsum=1.\n",
      "Finished 648 episode.rewardsum=1.\n",
      "Finished 649 episode.rewardsum=1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 650 episode.rewardsum=1.\n",
      "Finished 651 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 652 episode.rewardsum=1.\n",
      "Finished 653 episode.rewardsum=1.\n",
      "Finished 654 episode.rewardsum=1.\n",
      "Finished 655 episode.rewardsum=1.\n",
      "Finished 656 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 657 episode.rewardsum=1.\n",
      "Finished 658 episode.rewardsum=1.\n",
      "Finished 659 episode.rewardsum=1.\n",
      "Finished 660 episode.rewardsum=1.\n",
      "Finished 661 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 662 episode.rewardsum=1.\n",
      "Finished 663 episode.rewardsum=1.\n",
      "Finished 664 episode.rewardsum=1.\n",
      "Finished 665 episode.rewardsum=1.\n",
      "Finished 666 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 667 episode.rewardsum=1.\n",
      "Finished 668 episode.rewardsum=1.\n",
      "Finished 669 episode.rewardsum=1.\n",
      "Finished 670 episode.rewardsum=1.\n",
      "Finished 671 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 672 episode.rewardsum=1.\n",
      "Finished 673 episode.rewardsum=1.\n",
      "Finished 674 episode.rewardsum=1.\n",
      "Finished 675 episode.rewardsum=1.\n",
      "Finished 676 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 677 episode.rewardsum=1.\n",
      "Finished 678 episode.rewardsum=1.\n",
      "Finished 679 episode.rewardsum=1.\n",
      "Finished 680 episode.rewardsum=1.\n",
      "Finished 681 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 682 episode.rewardsum=1.\n",
      "Finished 683 episode.rewardsum=1.\n",
      "Finished 684 episode.rewardsum=1.\n",
      "Finished 685 episode.rewardsum=1.\n",
      "Finished 686 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 687 episode.rewardsum=0.\n",
      "Finished 688 episode.rewardsum=1.\n",
      "Finished 689 episode.rewardsum=1.\n",
      "Finished 690 episode.rewardsum=1.\n",
      "Finished 691 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 692 episode.rewardsum=1.\n",
      "Finished 693 episode.rewardsum=1.\n",
      "Finished 694 episode.rewardsum=1.\n",
      "Finished 695 episode.rewardsum=1.\n",
      "Finished 696 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 697 episode.rewardsum=1.\n",
      "Finished 698 episode.rewardsum=1.\n",
      "Finished 699 episode.rewardsum=1.\n",
      "Finished 700 episode.rewardsum=1.\n",
      "Finished 701 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 702 episode.rewardsum=1.\n",
      "Finished 703 episode.rewardsum=1.\n",
      "Finished 704 episode.rewardsum=1.\n",
      "Finished 705 episode.rewardsum=1.\n",
      "Finished 706 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 707 episode.rewardsum=1.\n",
      "Finished 708 episode.rewardsum=1.\n",
      "Finished 709 episode.rewardsum=1.\n",
      "Finished 710 episode.rewardsum=1.\n",
      "Finished 711 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 712 episode.rewardsum=1.\n",
      "Finished 713 episode.rewardsum=1.\n",
      "Finished 714 episode.rewardsum=1.\n",
      "Finished 715 episode.rewardsum=1.\n",
      "Finished 716 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 717 episode.rewardsum=1.\n",
      "Finished 718 episode.rewardsum=1.\n",
      "Finished 719 episode.rewardsum=1.\n",
      "Finished 720 episode.rewardsum=1.\n",
      "Finished 721 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 722 episode.rewardsum=1.\n",
      "Finished 723 episode.rewardsum=1.\n",
      "Finished 724 episode.rewardsum=1.\n",
      "Finished 725 episode.rewardsum=1.\n",
      "Finished 726 episode.rewardsum=0.\n",
      "Evaluation reward=1.\n",
      "Finished 727 episode.rewardsum=1.\n",
      "Finished 728 episode.rewardsum=0.\n",
      "Finished 729 episode.rewardsum=0.\n",
      "Finished 730 episode.rewardsum=1.\n",
      "Finished 731 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 732 episode.rewardsum=1.\n",
      "Finished 733 episode.rewardsum=0.\n",
      "Finished 734 episode.rewardsum=1.\n",
      "Finished 735 episode.rewardsum=1.\n",
      "Finished 736 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 737 episode.rewardsum=1.\n",
      "Finished 738 episode.rewardsum=1.\n",
      "Finished 739 episode.rewardsum=1.\n",
      "Finished 740 episode.rewardsum=1.\n",
      "Finished 741 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 742 episode.rewardsum=1.\n",
      "Finished 743 episode.rewardsum=1.\n",
      "Finished 744 episode.rewardsum=1.\n",
      "Finished 745 episode.rewardsum=1.\n",
      "Finished 746 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 747 episode.rewardsum=1.\n",
      "Finished 748 episode.rewardsum=1.\n",
      "Finished 749 episode.rewardsum=1.\n",
      "Finished 750 episode.rewardsum=1.\n",
      "Finished 751 episode.rewardsum=0.\n",
      "Evaluation reward=0.\n",
      "Finished 752 episode.rewardsum=1.\n",
      "Finished 753 episode.rewardsum=1.\n",
      "Finished 754 episode.rewardsum=1.\n",
      "Finished 755 episode.rewardsum=1.\n",
      "Finished 756 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 757 episode.rewardsum=1.\n",
      "Finished 758 episode.rewardsum=1.\n",
      "Finished 759 episode.rewardsum=1.\n",
      "Finished 760 episode.rewardsum=1.\n",
      "Finished 761 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 762 episode.rewardsum=1.\n",
      "Finished 763 episode.rewardsum=1.\n",
      "Finished 764 episode.rewardsum=1.\n",
      "Finished 765 episode.rewardsum=1.\n",
      "Finished 766 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 767 episode.rewardsum=1.\n",
      "Finished 768 episode.rewardsum=1.\n",
      "Finished 769 episode.rewardsum=1.\n",
      "Finished 770 episode.rewardsum=1.\n",
      "Finished 771 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 772 episode.rewardsum=1.\n",
      "Finished 773 episode.rewardsum=1.\n",
      "Finished 774 episode.rewardsum=1.\n",
      "Finished 775 episode.rewardsum=1.\n",
      "Finished 776 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 777 episode.rewardsum=1.\n",
      "Finished 778 episode.rewardsum=1.\n",
      "Finished 779 episode.rewardsum=1.\n",
      "Finished 780 episode.rewardsum=1.\n",
      "Finished 781 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 782 episode.rewardsum=1.\n",
      "Finished 783 episode.rewardsum=1.\n",
      "Finished 784 episode.rewardsum=1.\n",
      "Finished 785 episode.rewardsum=1.\n",
      "Finished 786 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 787 episode.rewardsum=1.\n",
      "Finished 788 episode.rewardsum=1.\n",
      "Finished 789 episode.rewardsum=1.\n",
      "Finished 790 episode.rewardsum=1.\n",
      "Finished 791 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 792 episode.rewardsum=1.\n",
      "Finished 793 episode.rewardsum=1.\n",
      "Finished 794 episode.rewardsum=1.\n",
      "Finished 795 episode.rewardsum=1.\n",
      "Finished 796 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 797 episode.rewardsum=1.\n",
      "Finished 798 episode.rewardsum=1.\n",
      "Finished 799 episode.rewardsum=1.\n",
      "Finished 800 episode.rewardsum=1.\n",
      "Finished 801 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 802 episode.rewardsum=1.\n",
      "Finished 803 episode.rewardsum=1.\n",
      "Finished 804 episode.rewardsum=1.\n",
      "Finished 805 episode.rewardsum=1.\n",
      "Finished 806 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 807 episode.rewardsum=1.\n",
      "Finished 808 episode.rewardsum=1.\n",
      "Finished 809 episode.rewardsum=1.\n",
      "Finished 810 episode.rewardsum=1.\n",
      "Finished 811 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 812 episode.rewardsum=1.\n",
      "Finished 813 episode.rewardsum=1.\n",
      "Finished 814 episode.rewardsum=1.\n",
      "Finished 815 episode.rewardsum=1.\n",
      "Finished 816 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 817 episode.rewardsum=1.\n",
      "Finished 818 episode.rewardsum=1.\n",
      "Finished 819 episode.rewardsum=1.\n",
      "Finished 820 episode.rewardsum=1.\n",
      "Finished 821 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 822 episode.rewardsum=1.\n",
      "Finished 823 episode.rewardsum=1.\n",
      "Finished 824 episode.rewardsum=1.\n",
      "Finished 825 episode.rewardsum=1.\n",
      "Finished 826 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 827 episode.rewardsum=1.\n",
      "Finished 828 episode.rewardsum=1.\n",
      "Finished 829 episode.rewardsum=1.\n",
      "Finished 830 episode.rewardsum=1.\n",
      "Finished 831 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 832 episode.rewardsum=1.\n",
      "Finished 833 episode.rewardsum=1.\n",
      "Finished 834 episode.rewardsum=1.\n",
      "Finished 835 episode.rewardsum=1.\n",
      "Finished 836 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 837 episode.rewardsum=1.\n",
      "Finished 838 episode.rewardsum=1.\n",
      "Finished 839 episode.rewardsum=1.\n",
      "Finished 840 episode.rewardsum=1.\n",
      "Finished 841 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 842 episode.rewardsum=1.\n",
      "Finished 843 episode.rewardsum=1.\n",
      "Finished 844 episode.rewardsum=1.\n",
      "Finished 845 episode.rewardsum=1.\n",
      "Finished 846 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 847 episode.rewardsum=1.\n",
      "Finished 848 episode.rewardsum=1.\n",
      "Finished 849 episode.rewardsum=1.\n",
      "Finished 850 episode.rewardsum=1.\n",
      "Finished 851 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 852 episode.rewardsum=1.\n",
      "Finished 853 episode.rewardsum=1.\n",
      "Finished 854 episode.rewardsum=1.\n",
      "Finished 855 episode.rewardsum=1.\n",
      "Finished 856 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 857 episode.rewardsum=1.\n",
      "Finished 858 episode.rewardsum=1.\n",
      "Finished 859 episode.rewardsum=1.\n",
      "Finished 860 episode.rewardsum=1.\n",
      "Finished 861 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 862 episode.rewardsum=1.\n",
      "Finished 863 episode.rewardsum=1.\n",
      "Finished 864 episode.rewardsum=1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 865 episode.rewardsum=1.\n",
      "Finished 866 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 867 episode.rewardsum=1.\n",
      "Finished 868 episode.rewardsum=1.\n",
      "Finished 869 episode.rewardsum=1.\n",
      "Finished 870 episode.rewardsum=1.\n",
      "Finished 871 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 872 episode.rewardsum=1.\n",
      "Finished 873 episode.rewardsum=1.\n",
      "Finished 874 episode.rewardsum=1.\n",
      "Finished 875 episode.rewardsum=1.\n",
      "Finished 876 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 877 episode.rewardsum=1.\n",
      "Finished 878 episode.rewardsum=1.\n",
      "Finished 879 episode.rewardsum=1.\n",
      "Finished 880 episode.rewardsum=1.\n",
      "Finished 881 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 882 episode.rewardsum=1.\n",
      "Finished 883 episode.rewardsum=1.\n",
      "Finished 884 episode.rewardsum=1.\n",
      "Finished 885 episode.rewardsum=1.\n",
      "Finished 886 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 887 episode.rewardsum=1.\n",
      "Finished 888 episode.rewardsum=1.\n",
      "Finished 889 episode.rewardsum=1.\n",
      "Finished 890 episode.rewardsum=1.\n",
      "Finished 891 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 892 episode.rewardsum=1.\n",
      "Finished 893 episode.rewardsum=1.\n",
      "Finished 894 episode.rewardsum=1.\n",
      "Finished 895 episode.rewardsum=1.\n",
      "Finished 896 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 897 episode.rewardsum=1.\n",
      "Finished 898 episode.rewardsum=1.\n",
      "Finished 899 episode.rewardsum=1.\n",
      "Finished 900 episode.rewardsum=1.\n",
      "Finished 901 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 902 episode.rewardsum=1.\n",
      "Finished 903 episode.rewardsum=1.\n",
      "Finished 904 episode.rewardsum=1.\n",
      "Finished 905 episode.rewardsum=1.\n",
      "Finished 906 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 907 episode.rewardsum=1.\n",
      "Finished 908 episode.rewardsum=1.\n",
      "Finished 909 episode.rewardsum=1.\n",
      "Finished 910 episode.rewardsum=1.\n",
      "Finished 911 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 912 episode.rewardsum=1.\n",
      "Finished 913 episode.rewardsum=1.\n",
      "Finished 914 episode.rewardsum=1.\n",
      "Finished 915 episode.rewardsum=1.\n",
      "Finished 916 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 917 episode.rewardsum=1.\n",
      "Finished 918 episode.rewardsum=1.\n",
      "Finished 919 episode.rewardsum=1.\n",
      "Finished 920 episode.rewardsum=1.\n",
      "Finished 921 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 922 episode.rewardsum=1.\n",
      "Finished 923 episode.rewardsum=1.\n",
      "Finished 924 episode.rewardsum=1.\n",
      "Finished 925 episode.rewardsum=1.\n",
      "Finished 926 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 927 episode.rewardsum=1.\n",
      "Finished 928 episode.rewardsum=1.\n",
      "Finished 929 episode.rewardsum=1.\n",
      "Finished 930 episode.rewardsum=1.\n",
      "Finished 931 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 932 episode.rewardsum=1.\n",
      "Finished 933 episode.rewardsum=1.\n",
      "Finished 934 episode.rewardsum=1.\n",
      "Finished 935 episode.rewardsum=1.\n",
      "Finished 936 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 937 episode.rewardsum=1.\n",
      "Finished 938 episode.rewardsum=1.\n",
      "Finished 939 episode.rewardsum=1.\n",
      "Finished 940 episode.rewardsum=1.\n",
      "Finished 941 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 942 episode.rewardsum=1.\n",
      "Finished 943 episode.rewardsum=1.\n",
      "Finished 944 episode.rewardsum=1.\n",
      "Finished 945 episode.rewardsum=1.\n",
      "Finished 946 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 947 episode.rewardsum=1.\n",
      "Finished 948 episode.rewardsum=1.\n",
      "Finished 949 episode.rewardsum=1.\n",
      "Finished 950 episode.rewardsum=1.\n",
      "Finished 951 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 952 episode.rewardsum=1.\n",
      "Finished 953 episode.rewardsum=1.\n",
      "Finished 954 episode.rewardsum=1.\n",
      "Finished 955 episode.rewardsum=1.\n",
      "Finished 956 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 957 episode.rewardsum=1.\n",
      "Finished 958 episode.rewardsum=1.\n",
      "Finished 959 episode.rewardsum=1.\n",
      "Finished 960 episode.rewardsum=1.\n",
      "Finished 961 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 962 episode.rewardsum=1.\n",
      "Finished 963 episode.rewardsum=1.\n",
      "Finished 964 episode.rewardsum=1.\n",
      "Finished 965 episode.rewardsum=1.\n",
      "Finished 966 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 967 episode.rewardsum=1.\n",
      "Finished 968 episode.rewardsum=1.\n",
      "Finished 969 episode.rewardsum=1.\n",
      "Finished 970 episode.rewardsum=1.\n",
      "Finished 971 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 972 episode.rewardsum=1.\n",
      "Finished 973 episode.rewardsum=1.\n",
      "Finished 974 episode.rewardsum=1.\n",
      "Finished 975 episode.rewardsum=1.\n",
      "Finished 976 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 977 episode.rewardsum=1.\n",
      "Finished 978 episode.rewardsum=1.\n",
      "Finished 979 episode.rewardsum=1.\n",
      "Finished 980 episode.rewardsum=1.\n",
      "Finished 981 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 982 episode.rewardsum=1.\n",
      "Finished 983 episode.rewardsum=1.\n",
      "Finished 984 episode.rewardsum=1.\n",
      "Finished 985 episode.rewardsum=1.\n",
      "Finished 986 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 987 episode.rewardsum=1.\n",
      "Finished 988 episode.rewardsum=1.\n",
      "Finished 989 episode.rewardsum=1.\n",
      "Finished 990 episode.rewardsum=1.\n",
      "Finished 991 episode.rewardsum=1.\n",
      "Evaluation reward=0.\n",
      "Finished 992 episode.rewardsum=1.\n",
      "Finished 993 episode.rewardsum=1.\n",
      "Finished 994 episode.rewardsum=1.\n",
      "Finished 995 episode.rewardsum=1.\n",
      "Finished 996 episode.rewardsum=1.\n",
      "Evaluation reward=1.\n",
      "Finished 997 episode.rewardsum=1.\n",
      "Finished 998 episode.rewardsum=1.\n",
      "Finished 999 episode.rewardsum=1.\n",
      "Finished 1000 episode.rewardsum=1.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# parameter initializations\n",
    "lr = 1e-3  # learning rate for gradient update\n",
    "batchsize = 64  # batchsize for buffer sampling\n",
    "maxlength = 10000  # max number of tuples held by buffer\n",
    "\n",
    "tau = 100  # time steps for target update\n",
    "episodes = 1000 # number of episodes to run\n",
    "initialsize = 500  # initial time steps before start updating\n",
    "epsilon_min = 0.01 # constant for exploration\n",
    "epsilon_decay = 0.999\n",
    "gamma = .99  # discount\n",
    "maxsteps = 100\n",
    "\n",
    "reward_record = []\n",
    "evaluation_record = []\n",
    "\n",
    "# initialize environment\n",
    "env = Qmaze(maze)\n",
    "obssize = 49\n",
    "actsize = num_actions\n",
    "\n",
    "# initialize tensorflow session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "# initialize networks\n",
    "with tf.variable_scope(\"principal\"):\n",
    "    Qprincipal = Qfunction(obssize, actsize, sess, optimizer)\n",
    "with tf.variable_scope(\"target\"):\n",
    "    Qtarget = Qfunction(obssize, actsize, sess, optimizer)\n",
    "\n",
    "# build ops\n",
    "update = build_target_update(\"principal\", \"target\")  # call sess.run(update) to copy\n",
    "                                                     # from principal to target\n",
    "\n",
    "# initialization of graph and buffer\n",
    "sess.run(tf.global_variables_initializer())\n",
    "buffer = ReplayBuffer(maxlength)\n",
    "sess.run(update)\n",
    "\n",
    "# main iteration\n",
    "# YOUR CODE HERE\n",
    "counter = 0\n",
    "epsilon =1.0\n",
    "for e in range(episodes):\n",
    "    env.reset(rat_cell)\n",
    "    done = 'not_over'\n",
    "    rewardsum = 0\n",
    "    epsilon = max(0.1,epsilon * 0.995)\n",
    "    \n",
    "    obs = env.observe()\n",
    "    \n",
    "    for _ in range(maxsteps):\n",
    "        valid_actions = env.valid_actions()\n",
    "        if not valid_actions: break\n",
    "        counter = counter + 1\n",
    "        \n",
    "        if np.random.rand() < epsilon:\n",
    "            action = random.choice(valid_actions)\n",
    "        else:\n",
    "            values = Qprincipal.compute_Qvalues(obs)\n",
    "            action = np.argmax(values)\n",
    "\n",
    "\n",
    "        obs_, reward, done = env.act(action)\n",
    "        \n",
    "        rewardsum += reward\n",
    "        \n",
    "        #Implement buffer replay to store memory\n",
    "        experience = (obs, action, reward, obs_)\n",
    "        buffer.append(experience)\n",
    "        buffer.pop()\n",
    "        \n",
    "            \n",
    "        if counter>initialsize and counter%5 == 0:\n",
    "            #Sample from stored memory\n",
    "            Samples = buffer.sample(batchsize)\n",
    "\n",
    "            #Conpute target_i\n",
    "            states = []\n",
    "            actions = []\n",
    "            targets = []\n",
    "            for i in range(len(Samples)):\n",
    "                s_current, action, r, s_next = Samples[i]\n",
    "                Q_target = Qtarget.compute_Qvalues(s_next)\n",
    "                states.extend(s_current)\n",
    "                actions.append(action)\n",
    "                target = r + gamma * np.max(Q_target)\n",
    "                targets.append(target)\n",
    "\n",
    "            #Compute empirical loss, update theta\n",
    "            Qprincipal.train(states, actions, targets)\n",
    "            \n",
    "        #Update target network\n",
    "        if counter % tau == 0:\n",
    "            sess.run(update)\n",
    "        if done == 'win':\n",
    "            break\n",
    "            \n",
    "        #Swap observation\n",
    "        obs = obs_\n",
    "    reward_record.append(rewardsum)\n",
    "    \n",
    "   \n",
    "    print('Finished {} episode.rewardsum={}.'.format(e+1,rewardsum))\n",
    "    show(env, file_name = 'maze/Maze'+'test_1_'+str(e+1))\n",
    "    \n",
    "    ## Define a evaluation episode\n",
    "    if e % 5 == 0:\n",
    "        env.reset(rat_cell)\n",
    "        done = 'not_over'\n",
    "        rewardsum = 0\n",
    "        \n",
    "        obs = env.observe()\n",
    "        \n",
    "        for _ in range(50):\n",
    "            values = Qprincipal.compute_Qvalues(obs)\n",
    "            action = np.argmax(values)\n",
    "            obs_, reward, done = env.act(action)\n",
    "\n",
    "            rewardsum += reward\n",
    "            \n",
    "            if done == 'win':\n",
    "                break\n",
    "            obs = obs_\n",
    "        evaluation_record.append(rewardsum)\n",
    "        print('Evaluation reward={}.'.format(rewardsum))\n",
    "        show(env, file_name = 'maze_evaluation/Maze'+'test_1_'+str(e+1))\n",
    "        with open('DQN_rewardsEval.dat', 'a') as eval_reward_file:\n",
    "             print(np.mean(evaluation_record[:-10]), file=eval_reward_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conge\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\conge\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    with open('DQN_rewardsEval_1.dat', 'a') as eval_reward_file:\n",
    "        if i < 10:\n",
    "            print(np.mean(evaluation_record[:i]), file=eval_reward_file)\n",
    "        else:\n",
    "            print(np.mean(evaluation_record[(i-10):i]), file=eval_reward_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
